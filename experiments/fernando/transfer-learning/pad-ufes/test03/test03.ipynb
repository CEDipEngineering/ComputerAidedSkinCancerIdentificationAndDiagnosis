{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "import os\n",
    "\n",
    "#basic\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "#tensorflow and keras\n",
    "from tensorflow import keras\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from tensorflow.keras.layers import Input, Dense, GlobalAveragePooling2D, Flatten, MaxPooling2D, Dropout, Resizing, Rescaling, RandomBrightness, RandomContrast, RandomCrop, RandomFlip, RandomRotation\n",
    "from keras.callbacks import ModelCheckpoint, EarlyStopping\n",
    "from keras import Model\n",
    "from keras.utils import load_img, img_to_array\n",
    "\n",
    "#sklearn\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "\n",
    "#open cv\n",
    "import cv2 as cv\n",
    "\n",
    "\n",
    "from cascid.configs import config, pad_ufes\n",
    "from cascid import database\n",
    "\n",
    "# Local py script\n",
    "#from model import *"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Globals"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "FERNANDO_PATH = config.DATA_DIR / 'experiments' / 'fernando'\n",
    "FERNANDO_PATH.mkdir(exist_ok=True, parents=True)\n",
    "\n",
    "IMAGE_CACHE = FERNANDO_PATH / 'img_cache.pkl'\n",
    "FEATURES_FILE = FERNANDO_PATH / 'features.pkl'\n",
    "MODEL_PATH = FERNANDO_PATH / 'models' / 'deep_learning'\n",
    "\n",
    "IMDIR = pad_ufes.IMAGES_DIR # Can also be pad_ufes.IMAGES_DIR "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "RANDOM_STATE = 42\n",
    "TRAIN_SIZE = 0.7\n",
    "VALIDATION_SIZE = 0.15\n",
    "TEST_SIZE = 0.15\n",
    "EPOCHS = 3000\n",
    "IMAGE_SHAPE = (64, 64, 3)\n",
    "BATCH_SIZE = 256"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_image(name: str):\n",
    "    pil_img = load_img(\n",
    "        str(IMDIR / name),\n",
    "        grayscale=False,\n",
    "        color_mode='rgb',\n",
    "        target_size=(IMAGE_SHAPE[0], IMAGE_SHAPE[1]),\n",
    "        interpolation='nearest',\n",
    "        keep_aspect_ratio=False\n",
    "    )\n",
    "\n",
    "    return img_to_array(pil_img, dtype=np.uint8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = database.get_db()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2298, 26)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "MulticlassEncoder = OneHotEncoder(sparse=False) # OHE for y encoding\n",
    "Y = MulticlassEncoder.fit_transform(df[[\"diagnostic\"]].to_numpy())\n",
    "x_train, x_test, y_train, y_test = train_test_split(df[\"img_id\"].to_numpy(), Y, test_size=0.2, random_state=RANDOM_STATE)\n",
    "x_train, x_valid, y_train, y_valid = train_test_split(x_train, y_train, test_size=0.2, random_state=RANDOM_STATE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "reader = lambda img_path_list : np.array(list(map(load_image, img_path_list)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "image_dict = {\n",
    "        \"train\": reader(x_train),\n",
    "        \"test\": reader(x_test),\n",
    "        \"valid\": reader(x_valid)\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Read operations done, cache file available at /home/fernandofincatti/.cascid_data/experiments/fernando/img_cache.pkl\n"
     ]
    }
   ],
   "source": [
    "# Write image cache\n",
    "with open(IMAGE_CACHE, 'wb') as file:\n",
    "    pickle.dump(image_dict, file)\n",
    "print(\"Read operations done, cache file available at {}\".format(IMAGE_CACHE))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Return to original variables\n",
    "x_train = image_dict[\"train\"]\n",
    "x_test = image_dict[\"test\"]\n",
    "x_valid = image_dict[\"valid\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-09-18 11:18:19.962389: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:975] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-09-18 11:18:19.973668: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:975] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-09-18 11:18:19.973971: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:975] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-09-18 11:18:19.974437: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2022-09-18 11:18:19.975173: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:975] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-09-18 11:18:19.975331: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:975] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-09-18 11:18:19.975432: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:975] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-09-18 11:18:20.304224: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:975] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-09-18 11:18:20.304379: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:975] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-09-18 11:18:20.304485: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:975] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-09-18 11:18:20.304569: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1532] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 4037 MB memory:  -> device: 0, name: NVIDIA GeForce RTX 2060, pci bus id: 0000:01:00.0, compute capability: 7.5\n"
     ]
    }
   ],
   "source": [
    "input_layer = keras.Sequential([\n",
    "    Rescaling(1./255), # Rescale from 0 to 255 UINT8 to 0 to 1 float.\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "augmentor = keras.Sequential([\n",
    "    RandomBrightness(factor=(-0.3, 0.3), value_range=(0.0, 1.0), seed=RANDOM_STATE), # Randomly change brightness anywhere from -30% to +30%\n",
    "    RandomContrast(factor=0.5, seed=RANDOM_STATE), # Randomly change contrast anywhere from -30% to +30%\n",
    "    RandomFlip(mode=\"horizontal_and_vertical\", seed=RANDOM_STATE), # Randomly flip images either horizontally, vertically or both\n",
    "    RandomRotation(factor=(-0.3, 0.3), fill_mode=\"nearest\", interpolation=\"bilinear\", seed=RANDOM_STATE), # Randomly rotate anywhere from -30% * 2PI to +30% * 2PI, filling gaps by using 'nearest' strategy\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "resnet = keras.applications.ResNet101(\n",
    "    weights='imagenet',\n",
    "    input_shape=IMAGE_SHAPE,\n",
    "    pooling='avg',\n",
    "    include_top=False\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "resnet.trainable = False  #to make sure it's not being trained\n",
    "# Augmentation only on training\n",
    "feature_extractor_train = keras.Sequential([\n",
    "    input_layer,\n",
    "    augmentor,\n",
    "    resnet\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test/Validation only get rescaled\n",
    "feature_extractor_test_valid = keras.Sequential([\n",
    "    input_layer,\n",
    "    resnet\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-09-18 11:18:23.021720: I tensorflow/stream_executor/cuda/cuda_dnn.cc:384] Loaded cuDNN version 8101\n"
     ]
    }
   ],
   "source": [
    "features_train = feature_extractor_train(x_train)\n",
    "features_valid = feature_extractor_test_valid(x_valid)\n",
    "features_test = feature_extractor_test_valid(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "features = {\n",
    "        \"train\": features_train.numpy(),\n",
    "        \"test\": features_test.numpy(),\n",
    "        \"valid\": features_valid.numpy(),\n",
    "        \"y_train\": y_train,\n",
    "        \"y_test\": y_test,\n",
    "        \"y_valid\": y_valid,\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(FEATURES_FILE, 'wb') as file:\n",
    "        pickle.dump(features, file)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(FEATURES_FILE, 'rb') as file:\n",
    "        features = pickle.load(file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train = features[\"train\"]\n",
    "x_test = features[\"test\"]\n",
    "x_valid = features[\"valid\"]\n",
    "y_train = features[\"y_train\"]\n",
    "y_test = features[\"y_test\"]\n",
    "y_valid = features[\"y_valid\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = keras.Sequential([\n",
    "    Input(shape = features[\"train\"].shape[1]),\n",
    "    Dense(128, activation='relu'),\n",
    "    Dropout(0.1),\n",
    "    Dense(128),\n",
    "    Dropout(0.1),\n",
    "    Dense(64),\n",
    "    Dropout(0.1),\n",
    "    Dense(y_train.shape[1], activation='softmax')\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(optimizer='adam',\n",
    "    loss='categorical_crossentropy',\n",
    "    metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "early_stopping = EarlyStopping(\n",
    "    monitor='val_accuracy',\n",
    "    mode='max',\n",
    "    verbose=1,\n",
    "    patience=200,\n",
    "    restore_best_weights=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/3000\n",
      "6/6 [==============================] - 0s 25ms/step - loss: 1.9380 - accuracy: 0.2721 - val_loss: 1.5529 - val_accuracy: 0.3946\n",
      "Epoch 2/3000\n",
      "6/6 [==============================] - 0s 5ms/step - loss: 1.6211 - accuracy: 0.3091 - val_loss: 1.5095 - val_accuracy: 0.3197\n",
      "Epoch 3/3000\n",
      "6/6 [==============================] - 0s 5ms/step - loss: 1.5621 - accuracy: 0.3409 - val_loss: 1.4999 - val_accuracy: 0.3197\n",
      "Epoch 4/3000\n",
      "6/6 [==============================] - 0s 5ms/step - loss: 1.5183 - accuracy: 0.3658 - val_loss: 1.4750 - val_accuracy: 0.3197\n",
      "Epoch 5/3000\n",
      "6/6 [==============================] - 0s 4ms/step - loss: 1.5044 - accuracy: 0.3553 - val_loss: 1.4616 - val_accuracy: 0.3197\n",
      "Epoch 6/3000\n",
      "6/6 [==============================] - 0s 5ms/step - loss: 1.5019 - accuracy: 0.3862 - val_loss: 1.4714 - val_accuracy: 0.3197\n",
      "Epoch 7/3000\n",
      "6/6 [==============================] - 0s 5ms/step - loss: 1.4999 - accuracy: 0.3583 - val_loss: 1.4669 - val_accuracy: 0.3265\n",
      "Epoch 8/3000\n",
      "6/6 [==============================] - 0s 5ms/step - loss: 1.4972 - accuracy: 0.3779 - val_loss: 1.4594 - val_accuracy: 0.4150\n",
      "Epoch 9/3000\n",
      "6/6 [==============================] - 0s 5ms/step - loss: 1.4919 - accuracy: 0.3681 - val_loss: 1.4608 - val_accuracy: 0.3265\n",
      "Epoch 10/3000\n",
      "6/6 [==============================] - 0s 5ms/step - loss: 1.4938 - accuracy: 0.3560 - val_loss: 1.4631 - val_accuracy: 0.3333\n",
      "Epoch 11/3000\n",
      "6/6 [==============================] - 0s 5ms/step - loss: 1.4925 - accuracy: 0.3757 - val_loss: 1.4702 - val_accuracy: 0.3265\n",
      "Epoch 12/3000\n",
      "6/6 [==============================] - 0s 5ms/step - loss: 1.4816 - accuracy: 0.3787 - val_loss: 1.4689 - val_accuracy: 0.3265\n",
      "Epoch 13/3000\n",
      "6/6 [==============================] - 0s 5ms/step - loss: 1.4764 - accuracy: 0.3991 - val_loss: 1.4542 - val_accuracy: 0.3605\n",
      "Epoch 14/3000\n",
      "6/6 [==============================] - 0s 5ms/step - loss: 1.4797 - accuracy: 0.3855 - val_loss: 1.4508 - val_accuracy: 0.3946\n",
      "Epoch 15/3000\n",
      "6/6 [==============================] - 0s 5ms/step - loss: 1.4791 - accuracy: 0.3961 - val_loss: 1.4616 - val_accuracy: 0.3401\n",
      "Epoch 16/3000\n",
      "6/6 [==============================] - 0s 5ms/step - loss: 1.4662 - accuracy: 0.3961 - val_loss: 1.4478 - val_accuracy: 0.4422\n",
      "Epoch 17/3000\n",
      "6/6 [==============================] - 0s 5ms/step - loss: 1.4641 - accuracy: 0.3825 - val_loss: 1.4588 - val_accuracy: 0.3333\n",
      "Epoch 18/3000\n",
      "6/6 [==============================] - 0s 5ms/step - loss: 1.4531 - accuracy: 0.4263 - val_loss: 1.4441 - val_accuracy: 0.4422\n",
      "Epoch 19/3000\n",
      "6/6 [==============================] - 0s 5ms/step - loss: 1.4496 - accuracy: 0.4225 - val_loss: 1.4570 - val_accuracy: 0.3946\n",
      "Epoch 20/3000\n",
      "6/6 [==============================] - 0s 4ms/step - loss: 1.4408 - accuracy: 0.4331 - val_loss: 1.4514 - val_accuracy: 0.4218\n",
      "Epoch 21/3000\n",
      "6/6 [==============================] - 0s 5ms/step - loss: 1.4372 - accuracy: 0.4127 - val_loss: 1.4406 - val_accuracy: 0.4150\n",
      "Epoch 22/3000\n",
      "6/6 [==============================] - 0s 5ms/step - loss: 1.4380 - accuracy: 0.4180 - val_loss: 1.4264 - val_accuracy: 0.4558\n",
      "Epoch 23/3000\n",
      "6/6 [==============================] - 0s 4ms/step - loss: 1.4295 - accuracy: 0.4142 - val_loss: 1.4251 - val_accuracy: 0.4218\n",
      "Epoch 24/3000\n",
      "6/6 [==============================] - 0s 5ms/step - loss: 1.4344 - accuracy: 0.4051 - val_loss: 1.4191 - val_accuracy: 0.4218\n",
      "Epoch 25/3000\n",
      "6/6 [==============================] - 0s 5ms/step - loss: 1.4308 - accuracy: 0.4187 - val_loss: 1.5047 - val_accuracy: 0.3401\n",
      "Epoch 26/3000\n",
      "6/6 [==============================] - 0s 5ms/step - loss: 1.4342 - accuracy: 0.4029 - val_loss: 1.4208 - val_accuracy: 0.4422\n",
      "Epoch 27/3000\n",
      "6/6 [==============================] - 0s 5ms/step - loss: 1.4289 - accuracy: 0.3930 - val_loss: 1.4276 - val_accuracy: 0.4422\n",
      "Epoch 28/3000\n",
      "6/6 [==============================] - 0s 5ms/step - loss: 1.4083 - accuracy: 0.4346 - val_loss: 1.4352 - val_accuracy: 0.4422\n",
      "Epoch 29/3000\n",
      "6/6 [==============================] - 0s 4ms/step - loss: 1.4139 - accuracy: 0.4308 - val_loss: 1.4175 - val_accuracy: 0.4558\n",
      "Epoch 30/3000\n",
      "6/6 [==============================] - 0s 5ms/step - loss: 1.4072 - accuracy: 0.4308 - val_loss: 1.4432 - val_accuracy: 0.3946\n",
      "Epoch 31/3000\n",
      "6/6 [==============================] - 0s 5ms/step - loss: 1.4158 - accuracy: 0.4225 - val_loss: 1.4123 - val_accuracy: 0.4694\n",
      "Epoch 32/3000\n",
      "6/6 [==============================] - 0s 4ms/step - loss: 1.3918 - accuracy: 0.4482 - val_loss: 1.4252 - val_accuracy: 0.4286\n",
      "Epoch 33/3000\n",
      "6/6 [==============================] - 0s 4ms/step - loss: 1.3979 - accuracy: 0.4505 - val_loss: 1.4218 - val_accuracy: 0.4490\n",
      "Epoch 34/3000\n",
      "6/6 [==============================] - 0s 4ms/step - loss: 1.3941 - accuracy: 0.4437 - val_loss: 1.4106 - val_accuracy: 0.4694\n",
      "Epoch 35/3000\n",
      "6/6 [==============================] - 0s 5ms/step - loss: 1.3940 - accuracy: 0.4437 - val_loss: 1.4136 - val_accuracy: 0.4286\n",
      "Epoch 36/3000\n",
      "6/6 [==============================] - 0s 4ms/step - loss: 1.3928 - accuracy: 0.4460 - val_loss: 1.4246 - val_accuracy: 0.4490\n",
      "Epoch 37/3000\n",
      "6/6 [==============================] - 0s 5ms/step - loss: 1.3858 - accuracy: 0.4528 - val_loss: 1.4488 - val_accuracy: 0.3673\n",
      "Epoch 38/3000\n",
      "6/6 [==============================] - 0s 5ms/step - loss: 1.3900 - accuracy: 0.4407 - val_loss: 1.3993 - val_accuracy: 0.4626\n",
      "Epoch 39/3000\n",
      "6/6 [==============================] - 0s 5ms/step - loss: 1.3955 - accuracy: 0.4482 - val_loss: 1.4102 - val_accuracy: 0.4286\n",
      "Epoch 40/3000\n",
      "6/6 [==============================] - 0s 5ms/step - loss: 1.4113 - accuracy: 0.4278 - val_loss: 1.4094 - val_accuracy: 0.4490\n",
      "Epoch 41/3000\n",
      "6/6 [==============================] - 0s 5ms/step - loss: 1.3865 - accuracy: 0.4490 - val_loss: 1.4535 - val_accuracy: 0.3605\n",
      "Epoch 42/3000\n",
      "6/6 [==============================] - 0s 5ms/step - loss: 1.3812 - accuracy: 0.4475 - val_loss: 1.3979 - val_accuracy: 0.4830\n",
      "Epoch 43/3000\n",
      "6/6 [==============================] - 0s 5ms/step - loss: 1.3948 - accuracy: 0.4346 - val_loss: 1.3975 - val_accuracy: 0.4558\n",
      "Epoch 44/3000\n",
      "6/6 [==============================] - 0s 5ms/step - loss: 1.3841 - accuracy: 0.4392 - val_loss: 1.3942 - val_accuracy: 0.4558\n",
      "Epoch 45/3000\n",
      "6/6 [==============================] - 0s 5ms/step - loss: 1.3764 - accuracy: 0.4618 - val_loss: 1.3939 - val_accuracy: 0.4626\n",
      "Epoch 46/3000\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 1.3686 - accuracy: 0.4618 - val_loss: 1.4323 - val_accuracy: 0.3946\n",
      "Epoch 47/3000\n",
      "6/6 [==============================] - 0s 5ms/step - loss: 1.3664 - accuracy: 0.4671 - val_loss: 1.4088 - val_accuracy: 0.4422\n",
      "Epoch 48/3000\n",
      "6/6 [==============================] - 0s 5ms/step - loss: 1.3858 - accuracy: 0.4505 - val_loss: 1.4002 - val_accuracy: 0.4626\n",
      "Epoch 49/3000\n",
      "6/6 [==============================] - 0s 5ms/step - loss: 1.3886 - accuracy: 0.4452 - val_loss: 1.4220 - val_accuracy: 0.4558\n",
      "Epoch 50/3000\n",
      "6/6 [==============================] - 0s 5ms/step - loss: 1.3723 - accuracy: 0.4717 - val_loss: 1.4227 - val_accuracy: 0.3946\n",
      "Epoch 51/3000\n",
      "6/6 [==============================] - 0s 5ms/step - loss: 1.3698 - accuracy: 0.4414 - val_loss: 1.3915 - val_accuracy: 0.4694\n",
      "Epoch 52/3000\n",
      "6/6 [==============================] - 0s 5ms/step - loss: 1.3683 - accuracy: 0.4686 - val_loss: 1.3844 - val_accuracy: 0.4626\n",
      "Epoch 53/3000\n",
      "6/6 [==============================] - 0s 5ms/step - loss: 1.3770 - accuracy: 0.4565 - val_loss: 1.4127 - val_accuracy: 0.4286\n",
      "Epoch 54/3000\n",
      "6/6 [==============================] - 0s 5ms/step - loss: 1.3677 - accuracy: 0.4580 - val_loss: 1.4340 - val_accuracy: 0.4354\n",
      "Epoch 55/3000\n",
      "6/6 [==============================] - 0s 5ms/step - loss: 1.3629 - accuracy: 0.4641 - val_loss: 1.4066 - val_accuracy: 0.4354\n",
      "Epoch 56/3000\n",
      "6/6 [==============================] - 0s 5ms/step - loss: 1.3674 - accuracy: 0.4414 - val_loss: 1.3865 - val_accuracy: 0.4490\n",
      "Epoch 57/3000\n",
      "6/6 [==============================] - 0s 5ms/step - loss: 1.3668 - accuracy: 0.4565 - val_loss: 1.3820 - val_accuracy: 0.4898\n",
      "Epoch 58/3000\n",
      "6/6 [==============================] - 0s 5ms/step - loss: 1.3637 - accuracy: 0.4588 - val_loss: 1.4074 - val_accuracy: 0.4354\n",
      "Epoch 59/3000\n",
      "6/6 [==============================] - 0s 5ms/step - loss: 1.3481 - accuracy: 0.4807 - val_loss: 1.3930 - val_accuracy: 0.4830\n",
      "Epoch 60/3000\n",
      "6/6 [==============================] - 0s 5ms/step - loss: 1.3571 - accuracy: 0.4626 - val_loss: 1.4099 - val_accuracy: 0.4422\n",
      "Epoch 61/3000\n",
      "6/6 [==============================] - 0s 5ms/step - loss: 1.3910 - accuracy: 0.4633 - val_loss: 1.4002 - val_accuracy: 0.4626\n",
      "Epoch 62/3000\n",
      "6/6 [==============================] - 0s 5ms/step - loss: 1.3709 - accuracy: 0.4497 - val_loss: 1.3770 - val_accuracy: 0.4490\n",
      "Epoch 63/3000\n",
      "6/6 [==============================] - 0s 5ms/step - loss: 1.3556 - accuracy: 0.4588 - val_loss: 1.3858 - val_accuracy: 0.4694\n",
      "Epoch 64/3000\n",
      "6/6 [==============================] - 0s 5ms/step - loss: 1.3468 - accuracy: 0.4747 - val_loss: 1.3958 - val_accuracy: 0.4762\n",
      "Epoch 65/3000\n",
      "6/6 [==============================] - 0s 5ms/step - loss: 1.3592 - accuracy: 0.4626 - val_loss: 1.4034 - val_accuracy: 0.4558\n",
      "Epoch 66/3000\n",
      "6/6 [==============================] - 0s 5ms/step - loss: 1.3569 - accuracy: 0.4800 - val_loss: 1.4115 - val_accuracy: 0.4558\n",
      "Epoch 67/3000\n",
      "6/6 [==============================] - 0s 5ms/step - loss: 1.3565 - accuracy: 0.4709 - val_loss: 1.4209 - val_accuracy: 0.4150\n",
      "Epoch 68/3000\n",
      "6/6 [==============================] - 0s 5ms/step - loss: 1.3600 - accuracy: 0.4580 - val_loss: 1.3905 - val_accuracy: 0.4626\n",
      "Epoch 69/3000\n",
      "6/6 [==============================] - 0s 5ms/step - loss: 1.3560 - accuracy: 0.4641 - val_loss: 1.3929 - val_accuracy: 0.4830\n",
      "Epoch 70/3000\n",
      "6/6 [==============================] - 0s 5ms/step - loss: 1.3786 - accuracy: 0.4467 - val_loss: 1.3755 - val_accuracy: 0.4626\n",
      "Epoch 71/3000\n",
      "6/6 [==============================] - 0s 5ms/step - loss: 1.3559 - accuracy: 0.4724 - val_loss: 1.3796 - val_accuracy: 0.4830\n",
      "Epoch 72/3000\n",
      "6/6 [==============================] - 0s 5ms/step - loss: 1.3623 - accuracy: 0.4649 - val_loss: 1.3814 - val_accuracy: 0.4626\n",
      "Epoch 73/3000\n",
      "6/6 [==============================] - 0s 5ms/step - loss: 1.3433 - accuracy: 0.4717 - val_loss: 1.4606 - val_accuracy: 0.3946\n",
      "Epoch 74/3000\n",
      "6/6 [==============================] - 0s 5ms/step - loss: 1.3552 - accuracy: 0.4649 - val_loss: 1.4424 - val_accuracy: 0.3878\n",
      "Epoch 75/3000\n",
      "6/6 [==============================] - 0s 5ms/step - loss: 1.3635 - accuracy: 0.4429 - val_loss: 1.3885 - val_accuracy: 0.4626\n",
      "Epoch 76/3000\n",
      "6/6 [==============================] - 0s 5ms/step - loss: 1.3691 - accuracy: 0.4641 - val_loss: 1.3786 - val_accuracy: 0.4626\n",
      "Epoch 77/3000\n",
      "6/6 [==============================] - 0s 5ms/step - loss: 1.3408 - accuracy: 0.4815 - val_loss: 1.4100 - val_accuracy: 0.4286\n",
      "Epoch 78/3000\n",
      "6/6 [==============================] - 0s 5ms/step - loss: 1.3541 - accuracy: 0.4686 - val_loss: 1.3879 - val_accuracy: 0.4626\n",
      "Epoch 79/3000\n",
      "6/6 [==============================] - 0s 5ms/step - loss: 1.3468 - accuracy: 0.4785 - val_loss: 1.3915 - val_accuracy: 0.4490\n",
      "Epoch 80/3000\n",
      "6/6 [==============================] - 0s 5ms/step - loss: 1.3418 - accuracy: 0.4694 - val_loss: 1.3766 - val_accuracy: 0.4490\n",
      "Epoch 81/3000\n",
      "6/6 [==============================] - 0s 5ms/step - loss: 1.3441 - accuracy: 0.4890 - val_loss: 1.3879 - val_accuracy: 0.4626\n",
      "Epoch 82/3000\n",
      "6/6 [==============================] - 0s 5ms/step - loss: 1.3416 - accuracy: 0.4633 - val_loss: 1.3824 - val_accuracy: 0.4490\n",
      "Epoch 83/3000\n",
      "6/6 [==============================] - 0s 5ms/step - loss: 1.3360 - accuracy: 0.4830 - val_loss: 1.4388 - val_accuracy: 0.4422\n",
      "Epoch 84/3000\n",
      "6/6 [==============================] - 0s 5ms/step - loss: 1.3562 - accuracy: 0.4800 - val_loss: 1.4839 - val_accuracy: 0.3605\n",
      "Epoch 85/3000\n",
      "6/6 [==============================] - 0s 5ms/step - loss: 1.3765 - accuracy: 0.4558 - val_loss: 1.3980 - val_accuracy: 0.4422\n",
      "Epoch 86/3000\n",
      "6/6 [==============================] - 0s 5ms/step - loss: 1.3635 - accuracy: 0.4429 - val_loss: 1.3878 - val_accuracy: 0.4898\n",
      "Epoch 87/3000\n",
      "6/6 [==============================] - 0s 5ms/step - loss: 1.3485 - accuracy: 0.4709 - val_loss: 1.3781 - val_accuracy: 0.4626\n",
      "Epoch 88/3000\n",
      "6/6 [==============================] - 0s 5ms/step - loss: 1.3510 - accuracy: 0.4815 - val_loss: 1.4635 - val_accuracy: 0.3605\n",
      "Epoch 89/3000\n",
      "6/6 [==============================] - 0s 5ms/step - loss: 1.3597 - accuracy: 0.4558 - val_loss: 1.4006 - val_accuracy: 0.4286\n",
      "Epoch 90/3000\n",
      "6/6 [==============================] - 0s 5ms/step - loss: 1.3556 - accuracy: 0.4497 - val_loss: 1.3869 - val_accuracy: 0.4762\n",
      "Epoch 91/3000\n",
      "6/6 [==============================] - 0s 5ms/step - loss: 1.3594 - accuracy: 0.4603 - val_loss: 1.3663 - val_accuracy: 0.4694\n",
      "Epoch 92/3000\n",
      "6/6 [==============================] - 0s 5ms/step - loss: 1.3588 - accuracy: 0.4588 - val_loss: 1.4086 - val_accuracy: 0.4354\n",
      "Epoch 93/3000\n",
      "6/6 [==============================] - 0s 5ms/step - loss: 1.3444 - accuracy: 0.4732 - val_loss: 1.3823 - val_accuracy: 0.4626\n",
      "Epoch 94/3000\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 1.3332 - accuracy: 0.4822 - val_loss: 1.3881 - val_accuracy: 0.4558\n",
      "Epoch 95/3000\n",
      "6/6 [==============================] - 0s 5ms/step - loss: 1.3320 - accuracy: 0.4845 - val_loss: 1.3729 - val_accuracy: 0.4830\n",
      "Epoch 96/3000\n",
      "6/6 [==============================] - 0s 5ms/step - loss: 1.3238 - accuracy: 0.4890 - val_loss: 1.4128 - val_accuracy: 0.4490\n",
      "Epoch 97/3000\n",
      "6/6 [==============================] - 0s 5ms/step - loss: 1.3449 - accuracy: 0.4815 - val_loss: 1.3682 - val_accuracy: 0.4694\n",
      "Epoch 98/3000\n",
      "6/6 [==============================] - 0s 5ms/step - loss: 1.3273 - accuracy: 0.4845 - val_loss: 1.3723 - val_accuracy: 0.4830\n",
      "Epoch 99/3000\n",
      "6/6 [==============================] - 0s 5ms/step - loss: 1.3247 - accuracy: 0.5072 - val_loss: 1.3799 - val_accuracy: 0.4626\n",
      "Epoch 100/3000\n",
      "6/6 [==============================] - 0s 5ms/step - loss: 1.3253 - accuracy: 0.4868 - val_loss: 1.4224 - val_accuracy: 0.4218\n",
      "Epoch 101/3000\n",
      "6/6 [==============================] - 0s 5ms/step - loss: 1.3326 - accuracy: 0.4694 - val_loss: 1.3973 - val_accuracy: 0.4558\n",
      "Epoch 102/3000\n",
      "6/6 [==============================] - 0s 5ms/step - loss: 1.3268 - accuracy: 0.5026 - val_loss: 1.3698 - val_accuracy: 0.4762\n",
      "Epoch 103/3000\n",
      "6/6 [==============================] - 0s 5ms/step - loss: 1.3306 - accuracy: 0.4762 - val_loss: 1.3824 - val_accuracy: 0.4626\n",
      "Epoch 104/3000\n",
      "6/6 [==============================] - 0s 5ms/step - loss: 1.3282 - accuracy: 0.4807 - val_loss: 1.4280 - val_accuracy: 0.4354\n",
      "Epoch 105/3000\n",
      "6/6 [==============================] - 0s 5ms/step - loss: 1.3355 - accuracy: 0.4830 - val_loss: 1.3669 - val_accuracy: 0.4966\n",
      "Epoch 106/3000\n",
      "6/6 [==============================] - 0s 5ms/step - loss: 1.3493 - accuracy: 0.4709 - val_loss: 1.3677 - val_accuracy: 0.4694\n",
      "Epoch 107/3000\n",
      "6/6 [==============================] - 0s 5ms/step - loss: 1.3249 - accuracy: 0.4936 - val_loss: 1.3662 - val_accuracy: 0.4762\n",
      "Epoch 108/3000\n",
      "6/6 [==============================] - 0s 5ms/step - loss: 1.3270 - accuracy: 0.4936 - val_loss: 1.3713 - val_accuracy: 0.4694\n",
      "Epoch 109/3000\n",
      "6/6 [==============================] - 0s 5ms/step - loss: 1.3605 - accuracy: 0.4694 - val_loss: 1.3794 - val_accuracy: 0.4762\n",
      "Epoch 110/3000\n",
      "6/6 [==============================] - 0s 5ms/step - loss: 1.3348 - accuracy: 0.4890 - val_loss: 1.4005 - val_accuracy: 0.4286\n",
      "Epoch 111/3000\n",
      "6/6 [==============================] - 0s 5ms/step - loss: 1.3348 - accuracy: 0.4785 - val_loss: 1.3704 - val_accuracy: 0.4898\n",
      "Epoch 112/3000\n",
      "6/6 [==============================] - 0s 5ms/step - loss: 1.3385 - accuracy: 0.4800 - val_loss: 1.3895 - val_accuracy: 0.4762\n",
      "Epoch 113/3000\n",
      "6/6 [==============================] - 0s 5ms/step - loss: 1.3266 - accuracy: 0.4890 - val_loss: 1.4661 - val_accuracy: 0.3878\n",
      "Epoch 114/3000\n",
      "6/6 [==============================] - 0s 5ms/step - loss: 1.3590 - accuracy: 0.4520 - val_loss: 1.3590 - val_accuracy: 0.4830\n",
      "Epoch 115/3000\n",
      "6/6 [==============================] - 0s 5ms/step - loss: 1.3510 - accuracy: 0.4633 - val_loss: 1.3624 - val_accuracy: 0.4626\n",
      "Epoch 116/3000\n",
      "6/6 [==============================] - 0s 5ms/step - loss: 1.3324 - accuracy: 0.4792 - val_loss: 1.3812 - val_accuracy: 0.4626\n",
      "Epoch 117/3000\n",
      "6/6 [==============================] - 0s 5ms/step - loss: 1.3326 - accuracy: 0.4830 - val_loss: 1.4268 - val_accuracy: 0.4286\n",
      "Epoch 118/3000\n",
      "6/6 [==============================] - 0s 5ms/step - loss: 1.3269 - accuracy: 0.4890 - val_loss: 1.3635 - val_accuracy: 0.4558\n",
      "Epoch 119/3000\n",
      "6/6 [==============================] - 0s 5ms/step - loss: 1.3354 - accuracy: 0.4830 - val_loss: 1.3571 - val_accuracy: 0.4762\n",
      "Epoch 120/3000\n",
      "6/6 [==============================] - 0s 5ms/step - loss: 1.3241 - accuracy: 0.4898 - val_loss: 1.3752 - val_accuracy: 0.4626\n",
      "Epoch 121/3000\n",
      "6/6 [==============================] - 0s 4ms/step - loss: 1.3181 - accuracy: 0.4928 - val_loss: 1.3734 - val_accuracy: 0.4830\n",
      "Epoch 122/3000\n",
      "6/6 [==============================] - 0s 5ms/step - loss: 1.3269 - accuracy: 0.4921 - val_loss: 1.4298 - val_accuracy: 0.4082\n",
      "Epoch 123/3000\n",
      "6/6 [==============================] - 0s 5ms/step - loss: 1.3301 - accuracy: 0.4769 - val_loss: 1.3659 - val_accuracy: 0.4694\n",
      "Epoch 124/3000\n",
      "6/6 [==============================] - 0s 5ms/step - loss: 1.3207 - accuracy: 0.4792 - val_loss: 1.3692 - val_accuracy: 0.4830\n",
      "Epoch 125/3000\n",
      "6/6 [==============================] - 0s 5ms/step - loss: 1.3139 - accuracy: 0.4921 - val_loss: 1.3671 - val_accuracy: 0.4626\n",
      "Epoch 126/3000\n",
      "6/6 [==============================] - 0s 5ms/step - loss: 1.3106 - accuracy: 0.5004 - val_loss: 1.3660 - val_accuracy: 0.4966\n",
      "Epoch 127/3000\n",
      "6/6 [==============================] - 0s 5ms/step - loss: 1.3347 - accuracy: 0.4800 - val_loss: 1.3703 - val_accuracy: 0.4626\n",
      "Epoch 128/3000\n",
      "6/6 [==============================] - 0s 5ms/step - loss: 1.3411 - accuracy: 0.4792 - val_loss: 1.3951 - val_accuracy: 0.4626\n",
      "Epoch 129/3000\n",
      "6/6 [==============================] - 0s 4ms/step - loss: 1.3289 - accuracy: 0.4853 - val_loss: 1.3797 - val_accuracy: 0.4762\n",
      "Epoch 130/3000\n",
      "6/6 [==============================] - 0s 5ms/step - loss: 1.3187 - accuracy: 0.4898 - val_loss: 1.3660 - val_accuracy: 0.4694\n",
      "Epoch 131/3000\n",
      "6/6 [==============================] - 0s 5ms/step - loss: 1.3234 - accuracy: 0.4890 - val_loss: 1.3673 - val_accuracy: 0.4830\n",
      "Epoch 132/3000\n",
      "6/6 [==============================] - 0s 5ms/step - loss: 1.3095 - accuracy: 0.4951 - val_loss: 1.3631 - val_accuracy: 0.4762\n",
      "Epoch 133/3000\n",
      "6/6 [==============================] - 0s 5ms/step - loss: 1.3102 - accuracy: 0.4966 - val_loss: 1.3585 - val_accuracy: 0.4830\n",
      "Epoch 134/3000\n",
      "6/6 [==============================] - 0s 5ms/step - loss: 1.3164 - accuracy: 0.4898 - val_loss: 1.3838 - val_accuracy: 0.4762\n",
      "Epoch 135/3000\n",
      "6/6 [==============================] - 0s 5ms/step - loss: 1.3372 - accuracy: 0.4830 - val_loss: 1.3687 - val_accuracy: 0.4830\n",
      "Epoch 136/3000\n",
      "6/6 [==============================] - 0s 5ms/step - loss: 1.3162 - accuracy: 0.4875 - val_loss: 1.3958 - val_accuracy: 0.4422\n",
      "Epoch 137/3000\n",
      "6/6 [==============================] - 0s 5ms/step - loss: 1.3223 - accuracy: 0.4906 - val_loss: 1.3616 - val_accuracy: 0.4830\n",
      "Epoch 138/3000\n",
      "6/6 [==============================] - 0s 4ms/step - loss: 1.3150 - accuracy: 0.4951 - val_loss: 1.3608 - val_accuracy: 0.4694\n",
      "Epoch 139/3000\n",
      "6/6 [==============================] - 0s 5ms/step - loss: 1.3120 - accuracy: 0.5019 - val_loss: 1.3551 - val_accuracy: 0.4830\n",
      "Epoch 140/3000\n",
      "6/6 [==============================] - 0s 5ms/step - loss: 1.3167 - accuracy: 0.4951 - val_loss: 1.3571 - val_accuracy: 0.4898\n",
      "Epoch 141/3000\n",
      "6/6 [==============================] - 0s 5ms/step - loss: 1.3077 - accuracy: 0.4996 - val_loss: 1.3638 - val_accuracy: 0.4830\n",
      "Epoch 142/3000\n",
      "6/6 [==============================] - 0s 5ms/step - loss: 1.3092 - accuracy: 0.4966 - val_loss: 1.3732 - val_accuracy: 0.4966\n",
      "Epoch 143/3000\n",
      "6/6 [==============================] - 0s 5ms/step - loss: 1.3093 - accuracy: 0.4943 - val_loss: 1.3668 - val_accuracy: 0.4626\n",
      "Epoch 144/3000\n",
      "6/6 [==============================] - 0s 5ms/step - loss: 1.3231 - accuracy: 0.4815 - val_loss: 1.3554 - val_accuracy: 0.4762\n",
      "Epoch 145/3000\n",
      "6/6 [==============================] - 0s 5ms/step - loss: 1.3175 - accuracy: 0.4958 - val_loss: 1.3863 - val_accuracy: 0.4558\n",
      "Epoch 146/3000\n",
      "6/6 [==============================] - 0s 5ms/step - loss: 1.3089 - accuracy: 0.5019 - val_loss: 1.3793 - val_accuracy: 0.4694\n",
      "Epoch 147/3000\n",
      "6/6 [==============================] - 0s 5ms/step - loss: 1.3041 - accuracy: 0.4974 - val_loss: 1.4523 - val_accuracy: 0.4150\n",
      "Epoch 148/3000\n",
      "6/6 [==============================] - 0s 5ms/step - loss: 1.3328 - accuracy: 0.4807 - val_loss: 1.3669 - val_accuracy: 0.4830\n",
      "Epoch 149/3000\n",
      "6/6 [==============================] - 0s 5ms/step - loss: 1.3072 - accuracy: 0.4996 - val_loss: 1.4748 - val_accuracy: 0.3946\n",
      "Epoch 150/3000\n",
      "6/6 [==============================] - 0s 5ms/step - loss: 1.3445 - accuracy: 0.4807 - val_loss: 1.3632 - val_accuracy: 0.4898\n",
      "Epoch 151/3000\n",
      "6/6 [==============================] - 0s 5ms/step - loss: 1.3078 - accuracy: 0.4815 - val_loss: 1.3760 - val_accuracy: 0.4898\n",
      "Epoch 152/3000\n",
      "6/6 [==============================] - 0s 5ms/step - loss: 1.3362 - accuracy: 0.4981 - val_loss: 1.3594 - val_accuracy: 0.4898\n",
      "Epoch 153/3000\n",
      "6/6 [==============================] - 0s 5ms/step - loss: 1.3011 - accuracy: 0.4974 - val_loss: 1.3696 - val_accuracy: 0.4762\n",
      "Epoch 154/3000\n",
      "6/6 [==============================] - 0s 5ms/step - loss: 1.3048 - accuracy: 0.4974 - val_loss: 1.3891 - val_accuracy: 0.4354\n",
      "Epoch 155/3000\n",
      "6/6 [==============================] - 0s 5ms/step - loss: 1.3074 - accuracy: 0.4906 - val_loss: 1.3764 - val_accuracy: 0.4626\n",
      "Epoch 156/3000\n",
      "6/6 [==============================] - 0s 5ms/step - loss: 1.3235 - accuracy: 0.4966 - val_loss: 1.3616 - val_accuracy: 0.4898\n",
      "Epoch 157/3000\n",
      "6/6 [==============================] - 0s 5ms/step - loss: 1.3139 - accuracy: 0.4928 - val_loss: 1.3910 - val_accuracy: 0.4830\n",
      "Epoch 158/3000\n",
      "6/6 [==============================] - 0s 5ms/step - loss: 1.3503 - accuracy: 0.4717 - val_loss: 1.4642 - val_accuracy: 0.3673\n",
      "Epoch 159/3000\n",
      "6/6 [==============================] - 0s 5ms/step - loss: 1.3441 - accuracy: 0.4535 - val_loss: 1.3594 - val_accuracy: 0.4830\n",
      "Epoch 160/3000\n",
      "6/6 [==============================] - 0s 5ms/step - loss: 1.3194 - accuracy: 0.4837 - val_loss: 1.3671 - val_accuracy: 0.4762\n",
      "Epoch 161/3000\n",
      "6/6 [==============================] - 0s 4ms/step - loss: 1.3106 - accuracy: 0.4898 - val_loss: 1.3643 - val_accuracy: 0.4898\n",
      "Epoch 162/3000\n",
      "6/6 [==============================] - 0s 5ms/step - loss: 1.3292 - accuracy: 0.4747 - val_loss: 1.4142 - val_accuracy: 0.4014\n",
      "Epoch 163/3000\n",
      "6/6 [==============================] - 0s 5ms/step - loss: 1.3211 - accuracy: 0.4671 - val_loss: 1.3644 - val_accuracy: 0.4762\n",
      "Epoch 164/3000\n",
      "6/6 [==============================] - 0s 5ms/step - loss: 1.3233 - accuracy: 0.4724 - val_loss: 1.3762 - val_accuracy: 0.4762\n",
      "Epoch 165/3000\n",
      "6/6 [==============================] - 0s 5ms/step - loss: 1.3306 - accuracy: 0.4890 - val_loss: 1.3553 - val_accuracy: 0.4830\n",
      "Epoch 166/3000\n",
      "6/6 [==============================] - 0s 5ms/step - loss: 1.3501 - accuracy: 0.4717 - val_loss: 1.4957 - val_accuracy: 0.3741\n",
      "Epoch 167/3000\n",
      "6/6 [==============================] - 0s 4ms/step - loss: 1.3618 - accuracy: 0.4452 - val_loss: 1.3680 - val_accuracy: 0.4830\n",
      "Epoch 168/3000\n",
      "6/6 [==============================] - 0s 5ms/step - loss: 1.3166 - accuracy: 0.4868 - val_loss: 1.3615 - val_accuracy: 0.4830\n",
      "Epoch 169/3000\n",
      "6/6 [==============================] - 0s 5ms/step - loss: 1.2985 - accuracy: 0.4921 - val_loss: 1.3516 - val_accuracy: 0.4898\n",
      "Epoch 170/3000\n",
      "6/6 [==============================] - 0s 5ms/step - loss: 1.3183 - accuracy: 0.4913 - val_loss: 1.3739 - val_accuracy: 0.4422\n",
      "Epoch 171/3000\n",
      "6/6 [==============================] - 0s 5ms/step - loss: 1.3030 - accuracy: 0.4951 - val_loss: 1.3655 - val_accuracy: 0.4830\n",
      "Epoch 172/3000\n",
      "6/6 [==============================] - 0s 5ms/step - loss: 1.3011 - accuracy: 0.4860 - val_loss: 1.3705 - val_accuracy: 0.4898\n",
      "Epoch 173/3000\n",
      "6/6 [==============================] - 0s 5ms/step - loss: 1.3145 - accuracy: 0.4777 - val_loss: 1.3600 - val_accuracy: 0.4830\n",
      "Epoch 174/3000\n",
      "6/6 [==============================] - 0s 5ms/step - loss: 1.2979 - accuracy: 0.4890 - val_loss: 1.3637 - val_accuracy: 0.4830\n",
      "Epoch 175/3000\n",
      "6/6 [==============================] - 0s 5ms/step - loss: 1.2962 - accuracy: 0.5004 - val_loss: 1.3741 - val_accuracy: 0.4626\n",
      "Epoch 176/3000\n",
      "6/6 [==============================] - 0s 5ms/step - loss: 1.2978 - accuracy: 0.4883 - val_loss: 1.3862 - val_accuracy: 0.4422\n",
      "Epoch 177/3000\n",
      "6/6 [==============================] - 0s 5ms/step - loss: 1.3012 - accuracy: 0.4981 - val_loss: 1.3444 - val_accuracy: 0.4898\n",
      "Epoch 178/3000\n",
      "6/6 [==============================] - 0s 5ms/step - loss: 1.3044 - accuracy: 0.5026 - val_loss: 1.3502 - val_accuracy: 0.4762\n",
      "Epoch 179/3000\n",
      "6/6 [==============================] - 0s 5ms/step - loss: 1.2952 - accuracy: 0.4966 - val_loss: 1.3451 - val_accuracy: 0.5034\n",
      "Epoch 180/3000\n",
      "6/6 [==============================] - 0s 5ms/step - loss: 1.3004 - accuracy: 0.5079 - val_loss: 1.3641 - val_accuracy: 0.4830\n",
      "Epoch 181/3000\n",
      "6/6 [==============================] - 0s 5ms/step - loss: 1.3061 - accuracy: 0.4800 - val_loss: 1.3917 - val_accuracy: 0.4694\n",
      "Epoch 182/3000\n",
      "6/6 [==============================] - 0s 5ms/step - loss: 1.3108 - accuracy: 0.5011 - val_loss: 1.3626 - val_accuracy: 0.4422\n",
      "Epoch 183/3000\n",
      "6/6 [==============================] - 0s 5ms/step - loss: 1.3031 - accuracy: 0.4921 - val_loss: 1.3639 - val_accuracy: 0.4830\n",
      "Epoch 184/3000\n",
      "6/6 [==============================] - 0s 5ms/step - loss: 1.2985 - accuracy: 0.5004 - val_loss: 1.3502 - val_accuracy: 0.4898\n",
      "Epoch 185/3000\n",
      "6/6 [==============================] - 0s 5ms/step - loss: 1.3053 - accuracy: 0.5011 - val_loss: 1.3496 - val_accuracy: 0.4966\n",
      "Epoch 186/3000\n",
      "6/6 [==============================] - 0s 4ms/step - loss: 1.3461 - accuracy: 0.4868 - val_loss: 1.4088 - val_accuracy: 0.4082\n",
      "Epoch 187/3000\n",
      "6/6 [==============================] - 0s 5ms/step - loss: 1.3213 - accuracy: 0.4943 - val_loss: 1.3598 - val_accuracy: 0.4626\n",
      "Epoch 188/3000\n",
      "6/6 [==============================] - 0s 5ms/step - loss: 1.2928 - accuracy: 0.4928 - val_loss: 1.3525 - val_accuracy: 0.4898\n",
      "Epoch 189/3000\n",
      "6/6 [==============================] - 0s 5ms/step - loss: 1.2963 - accuracy: 0.4951 - val_loss: 1.4483 - val_accuracy: 0.3741\n",
      "Epoch 190/3000\n",
      "6/6 [==============================] - 0s 5ms/step - loss: 1.3170 - accuracy: 0.4641 - val_loss: 1.3426 - val_accuracy: 0.4694\n",
      "Epoch 191/3000\n",
      "6/6 [==============================] - 0s 5ms/step - loss: 1.3046 - accuracy: 0.4906 - val_loss: 1.3431 - val_accuracy: 0.4626\n",
      "Epoch 192/3000\n",
      "6/6 [==============================] - 0s 5ms/step - loss: 1.3275 - accuracy: 0.4807 - val_loss: 1.3465 - val_accuracy: 0.4694\n",
      "Epoch 193/3000\n",
      "6/6 [==============================] - 0s 5ms/step - loss: 1.3062 - accuracy: 0.4958 - val_loss: 1.3773 - val_accuracy: 0.4422\n",
      "Epoch 194/3000\n",
      "6/6 [==============================] - 0s 5ms/step - loss: 1.3024 - accuracy: 0.4860 - val_loss: 1.3672 - val_accuracy: 0.4762\n",
      "Epoch 195/3000\n",
      "6/6 [==============================] - 0s 5ms/step - loss: 1.2978 - accuracy: 0.5004 - val_loss: 1.3477 - val_accuracy: 0.4830\n",
      "Epoch 196/3000\n",
      "6/6 [==============================] - 0s 5ms/step - loss: 1.3122 - accuracy: 0.4777 - val_loss: 1.3652 - val_accuracy: 0.4966\n",
      "Epoch 197/3000\n",
      "6/6 [==============================] - 0s 5ms/step - loss: 1.3488 - accuracy: 0.4603 - val_loss: 1.3635 - val_accuracy: 0.4422\n",
      "Epoch 198/3000\n",
      "6/6 [==============================] - 0s 5ms/step - loss: 1.3715 - accuracy: 0.4928 - val_loss: 1.3892 - val_accuracy: 0.4422\n",
      "Epoch 199/3000\n",
      "6/6 [==============================] - 0s 5ms/step - loss: 1.3383 - accuracy: 0.4792 - val_loss: 1.3523 - val_accuracy: 0.5034\n",
      "Epoch 200/3000\n",
      "6/6 [==============================] - 0s 5ms/step - loss: 1.3129 - accuracy: 0.4837 - val_loss: 1.3563 - val_accuracy: 0.4966\n",
      "Epoch 201/3000\n",
      "6/6 [==============================] - 0s 5ms/step - loss: 1.3005 - accuracy: 0.4928 - val_loss: 1.3671 - val_accuracy: 0.4558\n",
      "Epoch 202/3000\n",
      "6/6 [==============================] - 0s 5ms/step - loss: 1.3013 - accuracy: 0.4906 - val_loss: 1.3490 - val_accuracy: 0.4898\n",
      "Epoch 203/3000\n",
      "6/6 [==============================] - 0s 5ms/step - loss: 1.2882 - accuracy: 0.5011 - val_loss: 1.3566 - val_accuracy: 0.4762\n",
      "Epoch 204/3000\n",
      "6/6 [==============================] - 0s 5ms/step - loss: 1.2871 - accuracy: 0.5072 - val_loss: 1.3588 - val_accuracy: 0.4694\n",
      "Epoch 205/3000\n",
      "6/6 [==============================] - 0s 8ms/step - loss: 1.2817 - accuracy: 0.5087 - val_loss: 1.3503 - val_accuracy: 0.4762\n",
      "Epoch 206/3000\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 1.2771 - accuracy: 0.5019 - val_loss: 1.3433 - val_accuracy: 0.4626\n",
      "Epoch 207/3000\n",
      "6/6 [==============================] - 0s 5ms/step - loss: 1.2948 - accuracy: 0.4989 - val_loss: 1.3455 - val_accuracy: 0.4898\n",
      "Epoch 208/3000\n",
      "6/6 [==============================] - 0s 5ms/step - loss: 1.3006 - accuracy: 0.4883 - val_loss: 1.3786 - val_accuracy: 0.4762\n",
      "Epoch 209/3000\n",
      "6/6 [==============================] - 0s 5ms/step - loss: 1.2996 - accuracy: 0.5034 - val_loss: 1.4022 - val_accuracy: 0.4354\n",
      "Epoch 210/3000\n",
      "6/6 [==============================] - 0s 5ms/step - loss: 1.3031 - accuracy: 0.4951 - val_loss: 1.3684 - val_accuracy: 0.5170\n",
      "Epoch 211/3000\n",
      "6/6 [==============================] - 0s 5ms/step - loss: 1.3160 - accuracy: 0.4928 - val_loss: 1.3461 - val_accuracy: 0.4966\n",
      "Epoch 212/3000\n",
      "6/6 [==============================] - 0s 5ms/step - loss: 1.3206 - accuracy: 0.4807 - val_loss: 1.3425 - val_accuracy: 0.4762\n",
      "Epoch 213/3000\n",
      "6/6 [==============================] - 0s 5ms/step - loss: 1.3099 - accuracy: 0.4989 - val_loss: 1.4195 - val_accuracy: 0.4286\n",
      "Epoch 214/3000\n",
      "6/6 [==============================] - 0s 5ms/step - loss: 1.3126 - accuracy: 0.4800 - val_loss: 1.3370 - val_accuracy: 0.4830\n",
      "Epoch 215/3000\n",
      "6/6 [==============================] - 0s 5ms/step - loss: 1.3030 - accuracy: 0.4936 - val_loss: 1.3434 - val_accuracy: 0.4830\n",
      "Epoch 216/3000\n",
      "6/6 [==============================] - 0s 5ms/step - loss: 1.2969 - accuracy: 0.4943 - val_loss: 1.4482 - val_accuracy: 0.3946\n",
      "Epoch 217/3000\n",
      "6/6 [==============================] - 0s 4ms/step - loss: 1.3443 - accuracy: 0.4664 - val_loss: 1.4058 - val_accuracy: 0.4762\n",
      "Epoch 218/3000\n",
      "6/6 [==============================] - 0s 5ms/step - loss: 1.3282 - accuracy: 0.4913 - val_loss: 1.3462 - val_accuracy: 0.4966\n",
      "Epoch 219/3000\n",
      "6/6 [==============================] - 0s 5ms/step - loss: 1.3083 - accuracy: 0.4981 - val_loss: 1.3460 - val_accuracy: 0.4898\n",
      "Epoch 220/3000\n",
      "6/6 [==============================] - 0s 5ms/step - loss: 1.3097 - accuracy: 0.4913 - val_loss: 1.3572 - val_accuracy: 0.5102\n",
      "Epoch 221/3000\n",
      "6/6 [==============================] - 0s 5ms/step - loss: 1.3003 - accuracy: 0.4958 - val_loss: 1.4239 - val_accuracy: 0.4422\n",
      "Epoch 222/3000\n",
      "6/6 [==============================] - 0s 5ms/step - loss: 1.3039 - accuracy: 0.4958 - val_loss: 1.3400 - val_accuracy: 0.4966\n",
      "Epoch 223/3000\n",
      "6/6 [==============================] - 0s 5ms/step - loss: 1.3080 - accuracy: 0.4996 - val_loss: 1.3458 - val_accuracy: 0.5034\n",
      "Epoch 224/3000\n",
      "6/6 [==============================] - 0s 5ms/step - loss: 1.2929 - accuracy: 0.4928 - val_loss: 1.3556 - val_accuracy: 0.4830\n",
      "Epoch 225/3000\n",
      "6/6 [==============================] - 0s 5ms/step - loss: 1.2839 - accuracy: 0.5079 - val_loss: 1.3884 - val_accuracy: 0.4422\n",
      "Epoch 226/3000\n",
      "6/6 [==============================] - 0s 5ms/step - loss: 1.2972 - accuracy: 0.4943 - val_loss: 1.3370 - val_accuracy: 0.4830\n",
      "Epoch 227/3000\n",
      "6/6 [==============================] - 0s 5ms/step - loss: 1.2795 - accuracy: 0.4958 - val_loss: 1.4221 - val_accuracy: 0.4286\n",
      "Epoch 228/3000\n",
      "6/6 [==============================] - 0s 5ms/step - loss: 1.2971 - accuracy: 0.4989 - val_loss: 1.3596 - val_accuracy: 0.4830\n",
      "Epoch 229/3000\n",
      "6/6 [==============================] - 0s 5ms/step - loss: 1.3129 - accuracy: 0.4868 - val_loss: 1.3772 - val_accuracy: 0.4762\n",
      "Epoch 230/3000\n",
      "6/6 [==============================] - 0s 5ms/step - loss: 1.3109 - accuracy: 0.4898 - val_loss: 1.3820 - val_accuracy: 0.4694\n",
      "Epoch 231/3000\n",
      "6/6 [==============================] - 0s 5ms/step - loss: 1.3023 - accuracy: 0.4989 - val_loss: 1.3604 - val_accuracy: 0.4830\n",
      "Epoch 232/3000\n",
      "6/6 [==============================] - 0s 5ms/step - loss: 1.3043 - accuracy: 0.5019 - val_loss: 1.3474 - val_accuracy: 0.5034\n",
      "Epoch 233/3000\n",
      "6/6 [==============================] - 0s 5ms/step - loss: 1.2982 - accuracy: 0.4928 - val_loss: 1.3633 - val_accuracy: 0.4830\n",
      "Epoch 234/3000\n",
      "6/6 [==============================] - 0s 4ms/step - loss: 1.2967 - accuracy: 0.5125 - val_loss: 1.3443 - val_accuracy: 0.4694\n",
      "Epoch 235/3000\n",
      "6/6 [==============================] - 0s 5ms/step - loss: 1.3037 - accuracy: 0.4868 - val_loss: 1.3668 - val_accuracy: 0.5102\n",
      "Epoch 236/3000\n",
      "6/6 [==============================] - 0s 5ms/step - loss: 1.3156 - accuracy: 0.4815 - val_loss: 1.3615 - val_accuracy: 0.4490\n",
      "Epoch 237/3000\n",
      "6/6 [==============================] - 0s 5ms/step - loss: 1.3173 - accuracy: 0.4996 - val_loss: 1.4011 - val_accuracy: 0.4422\n",
      "Epoch 238/3000\n",
      "6/6 [==============================] - 0s 5ms/step - loss: 1.3099 - accuracy: 0.4898 - val_loss: 1.3603 - val_accuracy: 0.5034\n",
      "Epoch 239/3000\n",
      "6/6 [==============================] - 0s 5ms/step - loss: 1.3255 - accuracy: 0.4732 - val_loss: 1.3405 - val_accuracy: 0.4898\n",
      "Epoch 240/3000\n",
      "6/6 [==============================] - 0s 5ms/step - loss: 1.3186 - accuracy: 0.4701 - val_loss: 1.4038 - val_accuracy: 0.4014\n",
      "Epoch 241/3000\n",
      "6/6 [==============================] - 0s 5ms/step - loss: 1.3024 - accuracy: 0.4883 - val_loss: 1.3407 - val_accuracy: 0.5034\n",
      "Epoch 242/3000\n",
      "6/6 [==============================] - 0s 5ms/step - loss: 1.2842 - accuracy: 0.5019 - val_loss: 1.3444 - val_accuracy: 0.4898\n",
      "Epoch 243/3000\n",
      "6/6 [==============================] - 0s 5ms/step - loss: 1.2866 - accuracy: 0.5011 - val_loss: 1.4335 - val_accuracy: 0.4150\n",
      "Epoch 244/3000\n",
      "6/6 [==============================] - 0s 5ms/step - loss: 1.3194 - accuracy: 0.4921 - val_loss: 1.3454 - val_accuracy: 0.4490\n",
      "Epoch 245/3000\n",
      "6/6 [==============================] - 0s 5ms/step - loss: 1.2958 - accuracy: 0.4974 - val_loss: 1.3380 - val_accuracy: 0.4830\n",
      "Epoch 246/3000\n",
      "6/6 [==============================] - 0s 5ms/step - loss: 1.2952 - accuracy: 0.4822 - val_loss: 1.3593 - val_accuracy: 0.4558\n",
      "Epoch 247/3000\n",
      "6/6 [==============================] - 0s 5ms/step - loss: 1.2787 - accuracy: 0.4996 - val_loss: 1.3595 - val_accuracy: 0.4626\n",
      "Epoch 248/3000\n",
      "6/6 [==============================] - 0s 5ms/step - loss: 1.2803 - accuracy: 0.4996 - val_loss: 1.3566 - val_accuracy: 0.4762\n",
      "Epoch 249/3000\n",
      "6/6 [==============================] - 0s 5ms/step - loss: 1.2753 - accuracy: 0.5004 - val_loss: 1.3683 - val_accuracy: 0.4762\n",
      "Epoch 250/3000\n",
      "6/6 [==============================] - 0s 5ms/step - loss: 1.2782 - accuracy: 0.4996 - val_loss: 1.3444 - val_accuracy: 0.5034\n",
      "Epoch 251/3000\n",
      "6/6 [==============================] - 0s 5ms/step - loss: 1.2860 - accuracy: 0.5042 - val_loss: 1.3399 - val_accuracy: 0.4898\n",
      "Epoch 252/3000\n",
      "6/6 [==============================] - 0s 5ms/step - loss: 1.2834 - accuracy: 0.4981 - val_loss: 1.3408 - val_accuracy: 0.4694\n",
      "Epoch 253/3000\n",
      "6/6 [==============================] - 0s 5ms/step - loss: 1.2802 - accuracy: 0.5087 - val_loss: 1.3420 - val_accuracy: 0.4762\n",
      "Epoch 254/3000\n",
      "6/6 [==============================] - 0s 5ms/step - loss: 1.2860 - accuracy: 0.4936 - val_loss: 1.3469 - val_accuracy: 0.4830\n",
      "Epoch 255/3000\n",
      "6/6 [==============================] - 0s 5ms/step - loss: 1.2771 - accuracy: 0.5110 - val_loss: 1.3709 - val_accuracy: 0.4694\n",
      "Epoch 256/3000\n",
      "6/6 [==============================] - 0s 5ms/step - loss: 1.2825 - accuracy: 0.4913 - val_loss: 1.3792 - val_accuracy: 0.4558\n",
      "Epoch 257/3000\n",
      "6/6 [==============================] - 0s 5ms/step - loss: 1.2903 - accuracy: 0.4951 - val_loss: 1.3358 - val_accuracy: 0.5102\n",
      "Epoch 258/3000\n",
      "6/6 [==============================] - 0s 5ms/step - loss: 1.2871 - accuracy: 0.5079 - val_loss: 1.3353 - val_accuracy: 0.4966\n",
      "Epoch 259/3000\n",
      "6/6 [==============================] - 0s 5ms/step - loss: 1.2906 - accuracy: 0.5057 - val_loss: 1.3489 - val_accuracy: 0.4830\n",
      "Epoch 260/3000\n",
      "6/6 [==============================] - 0s 5ms/step - loss: 1.2902 - accuracy: 0.5026 - val_loss: 1.3815 - val_accuracy: 0.4422\n",
      "Epoch 261/3000\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 1.2844 - accuracy: 0.4951 - val_loss: 1.3525 - val_accuracy: 0.4626\n",
      "Epoch 262/3000\n",
      "6/6 [==============================] - 0s 5ms/step - loss: 1.2927 - accuracy: 0.4936 - val_loss: 1.3505 - val_accuracy: 0.4694\n",
      "Epoch 263/3000\n",
      "6/6 [==============================] - 0s 5ms/step - loss: 1.2731 - accuracy: 0.4996 - val_loss: 1.3395 - val_accuracy: 0.5102\n",
      "Epoch 264/3000\n",
      "6/6 [==============================] - 0s 5ms/step - loss: 1.2857 - accuracy: 0.5057 - val_loss: 1.3453 - val_accuracy: 0.5034\n",
      "Epoch 265/3000\n",
      "6/6 [==============================] - 0s 5ms/step - loss: 1.2828 - accuracy: 0.5200 - val_loss: 1.3552 - val_accuracy: 0.4422\n",
      "Epoch 266/3000\n",
      "6/6 [==============================] - 0s 5ms/step - loss: 1.2726 - accuracy: 0.4996 - val_loss: 1.3405 - val_accuracy: 0.4626\n",
      "Epoch 267/3000\n",
      "6/6 [==============================] - 0s 5ms/step - loss: 1.2875 - accuracy: 0.5094 - val_loss: 1.3437 - val_accuracy: 0.5034\n",
      "Epoch 268/3000\n",
      "6/6 [==============================] - 0s 5ms/step - loss: 1.2994 - accuracy: 0.4936 - val_loss: 1.3335 - val_accuracy: 0.4694\n",
      "Epoch 269/3000\n",
      "6/6 [==============================] - 0s 5ms/step - loss: 1.2945 - accuracy: 0.4996 - val_loss: 1.3427 - val_accuracy: 0.5102\n",
      "Epoch 270/3000\n",
      "6/6 [==============================] - 0s 5ms/step - loss: 1.2963 - accuracy: 0.5034 - val_loss: 1.3282 - val_accuracy: 0.4966\n",
      "Epoch 271/3000\n",
      "6/6 [==============================] - 0s 5ms/step - loss: 1.2887 - accuracy: 0.5042 - val_loss: 1.3992 - val_accuracy: 0.4286\n",
      "Epoch 272/3000\n",
      "6/6 [==============================] - 0s 5ms/step - loss: 1.2870 - accuracy: 0.5004 - val_loss: 1.3551 - val_accuracy: 0.4966\n",
      "Epoch 273/3000\n",
      "6/6 [==============================] - 0s 5ms/step - loss: 1.2659 - accuracy: 0.5049 - val_loss: 1.3573 - val_accuracy: 0.4898\n",
      "Epoch 274/3000\n",
      "6/6 [==============================] - 0s 5ms/step - loss: 1.2918 - accuracy: 0.5042 - val_loss: 1.3541 - val_accuracy: 0.4626\n",
      "Epoch 275/3000\n",
      "6/6 [==============================] - 0s 5ms/step - loss: 1.2797 - accuracy: 0.5042 - val_loss: 1.3947 - val_accuracy: 0.4422\n",
      "Epoch 276/3000\n",
      "6/6 [==============================] - 0s 5ms/step - loss: 1.2835 - accuracy: 0.5011 - val_loss: 1.3345 - val_accuracy: 0.4966\n",
      "Epoch 277/3000\n",
      "6/6 [==============================] - 0s 5ms/step - loss: 1.2776 - accuracy: 0.5132 - val_loss: 1.3343 - val_accuracy: 0.5034\n",
      "Epoch 278/3000\n",
      "6/6 [==============================] - 0s 5ms/step - loss: 1.2801 - accuracy: 0.4951 - val_loss: 1.3270 - val_accuracy: 0.4762\n",
      "Epoch 279/3000\n",
      "6/6 [==============================] - 0s 5ms/step - loss: 1.3150 - accuracy: 0.4868 - val_loss: 1.4559 - val_accuracy: 0.4082\n",
      "Epoch 280/3000\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 1.3089 - accuracy: 0.4868 - val_loss: 1.3352 - val_accuracy: 0.4762\n",
      "Epoch 281/3000\n",
      "6/6 [==============================] - 0s 5ms/step - loss: 1.2976 - accuracy: 0.4792 - val_loss: 1.3365 - val_accuracy: 0.5238\n",
      "Epoch 282/3000\n",
      "6/6 [==============================] - 0s 5ms/step - loss: 1.2637 - accuracy: 0.5125 - val_loss: 1.3374 - val_accuracy: 0.4898\n",
      "Epoch 283/3000\n",
      "6/6 [==============================] - 0s 5ms/step - loss: 1.2688 - accuracy: 0.5117 - val_loss: 1.3417 - val_accuracy: 0.4762\n",
      "Epoch 284/3000\n",
      "6/6 [==============================] - 0s 5ms/step - loss: 1.2705 - accuracy: 0.5034 - val_loss: 1.3423 - val_accuracy: 0.4762\n",
      "Epoch 285/3000\n",
      "6/6 [==============================] - 0s 5ms/step - loss: 1.2801 - accuracy: 0.5034 - val_loss: 1.3644 - val_accuracy: 0.4830\n",
      "Epoch 286/3000\n",
      "6/6 [==============================] - 0s 5ms/step - loss: 1.2693 - accuracy: 0.5170 - val_loss: 1.3664 - val_accuracy: 0.4626\n",
      "Epoch 287/3000\n",
      "6/6 [==============================] - 0s 5ms/step - loss: 1.2680 - accuracy: 0.5072 - val_loss: 1.3312 - val_accuracy: 0.5170\n",
      "Epoch 288/3000\n",
      "6/6 [==============================] - 0s 5ms/step - loss: 1.2764 - accuracy: 0.5026 - val_loss: 1.4041 - val_accuracy: 0.4218\n",
      "Epoch 289/3000\n",
      "6/6 [==============================] - 0s 5ms/step - loss: 1.2936 - accuracy: 0.4769 - val_loss: 1.3508 - val_accuracy: 0.5034\n",
      "Epoch 290/3000\n",
      "6/6 [==============================] - 0s 5ms/step - loss: 1.2707 - accuracy: 0.5117 - val_loss: 1.3372 - val_accuracy: 0.4966\n",
      "Epoch 291/3000\n",
      "6/6 [==============================] - 0s 5ms/step - loss: 1.2862 - accuracy: 0.5087 - val_loss: 1.3354 - val_accuracy: 0.5170\n",
      "Epoch 292/3000\n",
      "6/6 [==============================] - 0s 5ms/step - loss: 1.2618 - accuracy: 0.5072 - val_loss: 1.3616 - val_accuracy: 0.4694\n",
      "Epoch 293/3000\n",
      "6/6 [==============================] - 0s 5ms/step - loss: 1.2874 - accuracy: 0.4951 - val_loss: 1.3539 - val_accuracy: 0.4626\n",
      "Epoch 294/3000\n",
      "6/6 [==============================] - 0s 5ms/step - loss: 1.2648 - accuracy: 0.5102 - val_loss: 1.3383 - val_accuracy: 0.4898\n",
      "Epoch 295/3000\n",
      "6/6 [==============================] - 0s 5ms/step - loss: 1.2763 - accuracy: 0.5004 - val_loss: 1.3753 - val_accuracy: 0.4558\n",
      "Epoch 296/3000\n",
      "6/6 [==============================] - 0s 5ms/step - loss: 1.2559 - accuracy: 0.5087 - val_loss: 1.3261 - val_accuracy: 0.4830\n",
      "Epoch 297/3000\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 1.2688 - accuracy: 0.5049 - val_loss: 1.3237 - val_accuracy: 0.4694\n",
      "Epoch 298/3000\n",
      "6/6 [==============================] - 0s 5ms/step - loss: 1.2600 - accuracy: 0.5094 - val_loss: 1.3414 - val_accuracy: 0.4694\n",
      "Epoch 299/3000\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 1.2688 - accuracy: 0.5072 - val_loss: 1.3368 - val_accuracy: 0.4830\n",
      "Epoch 300/3000\n",
      "6/6 [==============================] - 0s 5ms/step - loss: 1.2671 - accuracy: 0.5132 - val_loss: 1.3295 - val_accuracy: 0.4830\n",
      "Epoch 301/3000\n",
      "6/6 [==============================] - 0s 5ms/step - loss: 1.2725 - accuracy: 0.5064 - val_loss: 1.3561 - val_accuracy: 0.4558\n",
      "Epoch 302/3000\n",
      "6/6 [==============================] - 0s 5ms/step - loss: 1.2596 - accuracy: 0.5042 - val_loss: 1.3637 - val_accuracy: 0.4694\n",
      "Epoch 303/3000\n",
      "6/6 [==============================] - 0s 4ms/step - loss: 1.2786 - accuracy: 0.5026 - val_loss: 1.3344 - val_accuracy: 0.4830\n",
      "Epoch 304/3000\n",
      "6/6 [==============================] - 0s 5ms/step - loss: 1.2611 - accuracy: 0.5147 - val_loss: 1.3256 - val_accuracy: 0.5102\n",
      "Epoch 305/3000\n",
      "6/6 [==============================] - 0s 5ms/step - loss: 1.2765 - accuracy: 0.5019 - val_loss: 1.3788 - val_accuracy: 0.4422\n",
      "Epoch 306/3000\n",
      "6/6 [==============================] - 0s 4ms/step - loss: 1.2572 - accuracy: 0.5087 - val_loss: 1.4205 - val_accuracy: 0.4422\n",
      "Epoch 307/3000\n",
      "6/6 [==============================] - 0s 5ms/step - loss: 1.2871 - accuracy: 0.4974 - val_loss: 1.3334 - val_accuracy: 0.4830\n",
      "Epoch 308/3000\n",
      "6/6 [==============================] - 0s 5ms/step - loss: 1.2777 - accuracy: 0.5087 - val_loss: 1.3252 - val_accuracy: 0.5102\n",
      "Epoch 309/3000\n",
      "6/6 [==============================] - 0s 5ms/step - loss: 1.2567 - accuracy: 0.5155 - val_loss: 1.3398 - val_accuracy: 0.4762\n",
      "Epoch 310/3000\n",
      "6/6 [==============================] - 0s 5ms/step - loss: 1.2611 - accuracy: 0.5155 - val_loss: 1.3381 - val_accuracy: 0.4966\n",
      "Epoch 311/3000\n",
      "6/6 [==============================] - 0s 5ms/step - loss: 1.2751 - accuracy: 0.5004 - val_loss: 1.3962 - val_accuracy: 0.4626\n",
      "Epoch 312/3000\n",
      "6/6 [==============================] - 0s 5ms/step - loss: 1.2796 - accuracy: 0.5110 - val_loss: 1.4498 - val_accuracy: 0.4218\n",
      "Epoch 313/3000\n",
      "6/6 [==============================] - 0s 5ms/step - loss: 1.3129 - accuracy: 0.4709 - val_loss: 1.3406 - val_accuracy: 0.4898\n",
      "Epoch 314/3000\n",
      "6/6 [==============================] - 0s 5ms/step - loss: 1.3080 - accuracy: 0.4837 - val_loss: 1.3378 - val_accuracy: 0.4898\n",
      "Epoch 315/3000\n",
      "6/6 [==============================] - 0s 5ms/step - loss: 1.3114 - accuracy: 0.4868 - val_loss: 1.4848 - val_accuracy: 0.3878\n",
      "Epoch 316/3000\n",
      "6/6 [==============================] - 0s 5ms/step - loss: 1.2926 - accuracy: 0.4981 - val_loss: 1.3555 - val_accuracy: 0.4558\n",
      "Epoch 317/3000\n",
      "6/6 [==============================] - 0s 5ms/step - loss: 1.2817 - accuracy: 0.4996 - val_loss: 1.3377 - val_accuracy: 0.4898\n",
      "Epoch 318/3000\n",
      "6/6 [==============================] - 0s 5ms/step - loss: 1.2650 - accuracy: 0.5057 - val_loss: 1.3260 - val_accuracy: 0.4898\n",
      "Epoch 319/3000\n",
      "6/6 [==============================] - 0s 5ms/step - loss: 1.2795 - accuracy: 0.5011 - val_loss: 1.3219 - val_accuracy: 0.5170\n",
      "Epoch 320/3000\n",
      "6/6 [==============================] - 0s 5ms/step - loss: 1.2824 - accuracy: 0.5004 - val_loss: 1.3481 - val_accuracy: 0.4490\n",
      "Epoch 321/3000\n",
      "6/6 [==============================] - 0s 5ms/step - loss: 1.2918 - accuracy: 0.5011 - val_loss: 1.3913 - val_accuracy: 0.4694\n",
      "Epoch 322/3000\n",
      "6/6 [==============================] - 0s 5ms/step - loss: 1.2904 - accuracy: 0.5026 - val_loss: 1.3529 - val_accuracy: 0.4694\n",
      "Epoch 323/3000\n",
      "6/6 [==============================] - 0s 5ms/step - loss: 1.2781 - accuracy: 0.4943 - val_loss: 1.4090 - val_accuracy: 0.4490\n",
      "Epoch 324/3000\n",
      "6/6 [==============================] - 0s 5ms/step - loss: 1.2947 - accuracy: 0.4898 - val_loss: 1.3289 - val_accuracy: 0.4830\n",
      "Epoch 325/3000\n",
      "6/6 [==============================] - 0s 5ms/step - loss: 1.2764 - accuracy: 0.5147 - val_loss: 1.3372 - val_accuracy: 0.5102\n",
      "Epoch 326/3000\n",
      "6/6 [==============================] - 0s 5ms/step - loss: 1.2539 - accuracy: 0.5231 - val_loss: 1.3318 - val_accuracy: 0.4830\n",
      "Epoch 327/3000\n",
      "6/6 [==============================] - 0s 5ms/step - loss: 1.2657 - accuracy: 0.5072 - val_loss: 1.3397 - val_accuracy: 0.5034\n",
      "Epoch 328/3000\n",
      "6/6 [==============================] - 0s 5ms/step - loss: 1.2541 - accuracy: 0.5178 - val_loss: 1.3422 - val_accuracy: 0.4830\n",
      "Epoch 329/3000\n",
      "6/6 [==============================] - 0s 5ms/step - loss: 1.2620 - accuracy: 0.5147 - val_loss: 1.3619 - val_accuracy: 0.4694\n",
      "Epoch 330/3000\n",
      "6/6 [==============================] - 0s 5ms/step - loss: 1.2550 - accuracy: 0.5117 - val_loss: 1.3353 - val_accuracy: 0.4966\n",
      "Epoch 331/3000\n",
      "6/6 [==============================] - 0s 5ms/step - loss: 1.2521 - accuracy: 0.5238 - val_loss: 1.3434 - val_accuracy: 0.4694\n",
      "Epoch 332/3000\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 1.2479 - accuracy: 0.5155 - val_loss: 1.3312 - val_accuracy: 0.4830\n",
      "Epoch 333/3000\n",
      "6/6 [==============================] - 0s 5ms/step - loss: 1.2583 - accuracy: 0.5102 - val_loss: 1.3309 - val_accuracy: 0.5034\n",
      "Epoch 334/3000\n",
      "6/6 [==============================] - 0s 5ms/step - loss: 1.2567 - accuracy: 0.5147 - val_loss: 1.3643 - val_accuracy: 0.4354\n",
      "Epoch 335/3000\n",
      "6/6 [==============================] - 0s 5ms/step - loss: 1.2641 - accuracy: 0.4906 - val_loss: 1.3158 - val_accuracy: 0.5034\n",
      "Epoch 336/3000\n",
      "6/6 [==============================] - 0s 5ms/step - loss: 1.2522 - accuracy: 0.5185 - val_loss: 1.3811 - val_accuracy: 0.4354\n",
      "Epoch 337/3000\n",
      "6/6 [==============================] - 0s 5ms/step - loss: 1.2640 - accuracy: 0.5049 - val_loss: 1.3467 - val_accuracy: 0.5306\n",
      "Epoch 338/3000\n",
      "6/6 [==============================] - 0s 5ms/step - loss: 1.2735 - accuracy: 0.5163 - val_loss: 1.4064 - val_accuracy: 0.4286\n",
      "Epoch 339/3000\n",
      "6/6 [==============================] - 0s 5ms/step - loss: 1.2634 - accuracy: 0.5170 - val_loss: 1.3204 - val_accuracy: 0.4762\n",
      "Epoch 340/3000\n",
      "6/6 [==============================] - 0s 5ms/step - loss: 1.2873 - accuracy: 0.4966 - val_loss: 1.3161 - val_accuracy: 0.5034\n",
      "Epoch 341/3000\n",
      "6/6 [==============================] - 0s 5ms/step - loss: 1.2633 - accuracy: 0.5004 - val_loss: 1.3798 - val_accuracy: 0.4694\n",
      "Epoch 342/3000\n",
      "6/6 [==============================] - 0s 5ms/step - loss: 1.2547 - accuracy: 0.4996 - val_loss: 1.3438 - val_accuracy: 0.4762\n",
      "Epoch 343/3000\n",
      "6/6 [==============================] - 0s 5ms/step - loss: 1.2550 - accuracy: 0.5087 - val_loss: 1.3611 - val_accuracy: 0.4422\n",
      "Epoch 344/3000\n",
      "6/6 [==============================] - 0s 5ms/step - loss: 1.2828 - accuracy: 0.5057 - val_loss: 1.3472 - val_accuracy: 0.5238\n",
      "Epoch 345/3000\n",
      "6/6 [==============================] - 0s 4ms/step - loss: 1.2617 - accuracy: 0.5147 - val_loss: 1.3501 - val_accuracy: 0.4830\n",
      "Epoch 346/3000\n",
      "6/6 [==============================] - 0s 5ms/step - loss: 1.2613 - accuracy: 0.5087 - val_loss: 1.3174 - val_accuracy: 0.4966\n",
      "Epoch 347/3000\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 1.2484 - accuracy: 0.5215 - val_loss: 1.3558 - val_accuracy: 0.5102\n",
      "Epoch 348/3000\n",
      "6/6 [==============================] - 0s 7ms/step - loss: 1.2933 - accuracy: 0.4989 - val_loss: 1.3401 - val_accuracy: 0.4830\n",
      "Epoch 349/3000\n",
      "6/6 [==============================] - 0s 5ms/step - loss: 1.2636 - accuracy: 0.5110 - val_loss: 1.3526 - val_accuracy: 0.4558\n",
      "Epoch 350/3000\n",
      "6/6 [==============================] - 0s 5ms/step - loss: 1.2614 - accuracy: 0.5094 - val_loss: 1.3206 - val_accuracy: 0.4830\n",
      "Epoch 351/3000\n",
      "6/6 [==============================] - 0s 5ms/step - loss: 1.2593 - accuracy: 0.5306 - val_loss: 1.3416 - val_accuracy: 0.5034\n",
      "Epoch 352/3000\n",
      "6/6 [==============================] - 0s 5ms/step - loss: 1.2567 - accuracy: 0.5170 - val_loss: 1.3994 - val_accuracy: 0.4354\n",
      "Epoch 353/3000\n",
      "6/6 [==============================] - 0s 5ms/step - loss: 1.2777 - accuracy: 0.4845 - val_loss: 1.3321 - val_accuracy: 0.4762\n",
      "Epoch 354/3000\n",
      "6/6 [==============================] - 0s 5ms/step - loss: 1.2558 - accuracy: 0.5147 - val_loss: 1.3370 - val_accuracy: 0.5034\n",
      "Epoch 355/3000\n",
      "6/6 [==============================] - 0s 5ms/step - loss: 1.2559 - accuracy: 0.5185 - val_loss: 1.3258 - val_accuracy: 0.4898\n",
      "Epoch 356/3000\n",
      "6/6 [==============================] - 0s 5ms/step - loss: 1.2453 - accuracy: 0.5283 - val_loss: 1.3285 - val_accuracy: 0.4558\n",
      "Epoch 357/3000\n",
      "6/6 [==============================] - 0s 5ms/step - loss: 1.2581 - accuracy: 0.5147 - val_loss: 1.3236 - val_accuracy: 0.4966\n",
      "Epoch 358/3000\n",
      "6/6 [==============================] - 0s 5ms/step - loss: 1.2605 - accuracy: 0.5170 - val_loss: 1.3418 - val_accuracy: 0.4898\n",
      "Epoch 359/3000\n",
      "6/6 [==============================] - 0s 5ms/step - loss: 1.2430 - accuracy: 0.5140 - val_loss: 1.3243 - val_accuracy: 0.5170\n",
      "Epoch 360/3000\n",
      "6/6 [==============================] - 0s 5ms/step - loss: 1.2490 - accuracy: 0.5102 - val_loss: 1.3298 - val_accuracy: 0.4898\n",
      "Epoch 361/3000\n",
      "6/6 [==============================] - 0s 5ms/step - loss: 1.2485 - accuracy: 0.5087 - val_loss: 1.4192 - val_accuracy: 0.4218\n",
      "Epoch 362/3000\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 1.2777 - accuracy: 0.5064 - val_loss: 1.3195 - val_accuracy: 0.4762\n",
      "Epoch 363/3000\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 1.2776 - accuracy: 0.5034 - val_loss: 1.3309 - val_accuracy: 0.4966\n",
      "Epoch 364/3000\n",
      "6/6 [==============================] - 0s 5ms/step - loss: 1.2740 - accuracy: 0.4966 - val_loss: 1.3344 - val_accuracy: 0.4830\n",
      "Epoch 365/3000\n",
      "6/6 [==============================] - 0s 5ms/step - loss: 1.2665 - accuracy: 0.4958 - val_loss: 1.3263 - val_accuracy: 0.4694\n",
      "Epoch 366/3000\n",
      "6/6 [==============================] - 0s 5ms/step - loss: 1.2622 - accuracy: 0.5026 - val_loss: 1.3321 - val_accuracy: 0.5170\n",
      "Epoch 367/3000\n",
      "6/6 [==============================] - 0s 5ms/step - loss: 1.2607 - accuracy: 0.5079 - val_loss: 1.3497 - val_accuracy: 0.5034\n",
      "Epoch 368/3000\n",
      "6/6 [==============================] - 0s 5ms/step - loss: 1.2573 - accuracy: 0.5132 - val_loss: 1.3520 - val_accuracy: 0.4558\n",
      "Epoch 369/3000\n",
      "6/6 [==============================] - 0s 5ms/step - loss: 1.2583 - accuracy: 0.5094 - val_loss: 1.3148 - val_accuracy: 0.4898\n",
      "Epoch 370/3000\n",
      "6/6 [==============================] - 0s 5ms/step - loss: 1.2565 - accuracy: 0.5094 - val_loss: 1.3241 - val_accuracy: 0.4966\n",
      "Epoch 371/3000\n",
      "6/6 [==============================] - 0s 5ms/step - loss: 1.2494 - accuracy: 0.5042 - val_loss: 1.3508 - val_accuracy: 0.4830\n",
      "Epoch 372/3000\n",
      "6/6 [==============================] - 0s 5ms/step - loss: 1.2464 - accuracy: 0.5238 - val_loss: 1.3618 - val_accuracy: 0.4490\n",
      "Epoch 373/3000\n",
      "6/6 [==============================] - 0s 5ms/step - loss: 1.2542 - accuracy: 0.5178 - val_loss: 1.3307 - val_accuracy: 0.4490\n",
      "Epoch 374/3000\n",
      "6/6 [==============================] - 0s 5ms/step - loss: 1.2538 - accuracy: 0.5155 - val_loss: 1.3371 - val_accuracy: 0.4830\n",
      "Epoch 375/3000\n",
      "6/6 [==============================] - 0s 5ms/step - loss: 1.2640 - accuracy: 0.5094 - val_loss: 1.3421 - val_accuracy: 0.4626\n",
      "Epoch 376/3000\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 1.3071 - accuracy: 0.4792 - val_loss: 1.3715 - val_accuracy: 0.4422\n",
      "Epoch 377/3000\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 1.2556 - accuracy: 0.5019 - val_loss: 1.3669 - val_accuracy: 0.4694\n",
      "Epoch 378/3000\n",
      "6/6 [==============================] - 0s 5ms/step - loss: 1.2820 - accuracy: 0.4883 - val_loss: 1.3365 - val_accuracy: 0.4762\n",
      "Epoch 379/3000\n",
      "6/6 [==============================] - 0s 5ms/step - loss: 1.2622 - accuracy: 0.5072 - val_loss: 1.3179 - val_accuracy: 0.4898\n",
      "Epoch 380/3000\n",
      "6/6 [==============================] - 0s 5ms/step - loss: 1.2646 - accuracy: 0.4958 - val_loss: 1.3193 - val_accuracy: 0.5170\n",
      "Epoch 381/3000\n",
      "6/6 [==============================] - 0s 4ms/step - loss: 1.2399 - accuracy: 0.5238 - val_loss: 1.3566 - val_accuracy: 0.4558\n",
      "Epoch 382/3000\n",
      "6/6 [==============================] - 0s 5ms/step - loss: 1.2543 - accuracy: 0.5163 - val_loss: 1.3604 - val_accuracy: 0.5238\n",
      "Epoch 383/3000\n",
      "6/6 [==============================] - 0s 5ms/step - loss: 1.2584 - accuracy: 0.5185 - val_loss: 1.3350 - val_accuracy: 0.4898\n",
      "Epoch 384/3000\n",
      "6/6 [==============================] - 0s 5ms/step - loss: 1.2708 - accuracy: 0.5019 - val_loss: 1.3471 - val_accuracy: 0.5238\n",
      "Epoch 385/3000\n",
      "6/6 [==============================] - 0s 5ms/step - loss: 1.2641 - accuracy: 0.5110 - val_loss: 1.3401 - val_accuracy: 0.4558\n",
      "Epoch 386/3000\n",
      "6/6 [==============================] - 0s 5ms/step - loss: 1.2520 - accuracy: 0.5132 - val_loss: 1.3255 - val_accuracy: 0.5102\n",
      "Epoch 387/3000\n",
      "6/6 [==============================] - 0s 5ms/step - loss: 1.2597 - accuracy: 0.5117 - val_loss: 1.3247 - val_accuracy: 0.4966\n",
      "Epoch 388/3000\n",
      "6/6 [==============================] - 0s 5ms/step - loss: 1.2633 - accuracy: 0.5064 - val_loss: 1.3591 - val_accuracy: 0.4490\n",
      "Epoch 389/3000\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 1.2775 - accuracy: 0.4989 - val_loss: 1.4440 - val_accuracy: 0.4286\n",
      "Epoch 390/3000\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 1.3195 - accuracy: 0.4739 - val_loss: 1.4287 - val_accuracy: 0.4014\n",
      "Epoch 391/3000\n",
      "6/6 [==============================] - 0s 5ms/step - loss: 1.3328 - accuracy: 0.4603 - val_loss: 1.3598 - val_accuracy: 0.5102\n",
      "Epoch 392/3000\n",
      "6/6 [==============================] - 0s 5ms/step - loss: 1.2913 - accuracy: 0.5079 - val_loss: 1.3479 - val_accuracy: 0.4694\n",
      "Epoch 393/3000\n",
      "6/6 [==============================] - 0s 5ms/step - loss: 1.2787 - accuracy: 0.4981 - val_loss: 1.3256 - val_accuracy: 0.4898\n",
      "Epoch 394/3000\n",
      "6/6 [==============================] - 0s 5ms/step - loss: 1.3066 - accuracy: 0.4936 - val_loss: 1.3405 - val_accuracy: 0.5170\n",
      "Epoch 395/3000\n",
      "6/6 [==============================] - 0s 5ms/step - loss: 1.2717 - accuracy: 0.5011 - val_loss: 1.3440 - val_accuracy: 0.4762\n",
      "Epoch 396/3000\n",
      "6/6 [==============================] - 0s 5ms/step - loss: 1.2804 - accuracy: 0.4974 - val_loss: 1.3352 - val_accuracy: 0.5102\n",
      "Epoch 397/3000\n",
      "6/6 [==============================] - 0s 5ms/step - loss: 1.2763 - accuracy: 0.4913 - val_loss: 1.3297 - val_accuracy: 0.4830\n",
      "Epoch 398/3000\n",
      "6/6 [==============================] - 0s 5ms/step - loss: 1.2650 - accuracy: 0.5049 - val_loss: 1.3271 - val_accuracy: 0.5034\n",
      "Epoch 399/3000\n",
      "6/6 [==============================] - 0s 5ms/step - loss: 1.2577 - accuracy: 0.5004 - val_loss: 1.3622 - val_accuracy: 0.4830\n",
      "Epoch 400/3000\n",
      "6/6 [==============================] - 0s 5ms/step - loss: 1.2662 - accuracy: 0.5155 - val_loss: 1.3268 - val_accuracy: 0.4694\n",
      "Epoch 401/3000\n",
      "6/6 [==============================] - 0s 5ms/step - loss: 1.2741 - accuracy: 0.4958 - val_loss: 1.3347 - val_accuracy: 0.5306\n",
      "Epoch 402/3000\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 1.2591 - accuracy: 0.5110 - val_loss: 1.3559 - val_accuracy: 0.4762\n",
      "Epoch 403/3000\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 1.2658 - accuracy: 0.5049 - val_loss: 1.4056 - val_accuracy: 0.4558\n",
      "Epoch 404/3000\n",
      "6/6 [==============================] - 0s 5ms/step - loss: 1.2651 - accuracy: 0.5132 - val_loss: 1.3528 - val_accuracy: 0.4830\n",
      "Epoch 405/3000\n",
      "6/6 [==============================] - 0s 5ms/step - loss: 1.2629 - accuracy: 0.5147 - val_loss: 1.3299 - val_accuracy: 0.5170\n",
      "Epoch 406/3000\n",
      "6/6 [==============================] - 0s 5ms/step - loss: 1.2578 - accuracy: 0.5163 - val_loss: 1.3853 - val_accuracy: 0.4490\n",
      "Epoch 407/3000\n",
      "6/6 [==============================] - 0s 5ms/step - loss: 1.2464 - accuracy: 0.5087 - val_loss: 1.3625 - val_accuracy: 0.4762\n",
      "Epoch 408/3000\n",
      "6/6 [==============================] - 0s 5ms/step - loss: 1.2594 - accuracy: 0.5049 - val_loss: 1.3342 - val_accuracy: 0.4898\n",
      "Epoch 409/3000\n",
      "6/6 [==============================] - 0s 5ms/step - loss: 1.2823 - accuracy: 0.5049 - val_loss: 1.3474 - val_accuracy: 0.5102\n",
      "Epoch 410/3000\n",
      "6/6 [==============================] - 0s 5ms/step - loss: 1.3387 - accuracy: 0.4641 - val_loss: 1.4628 - val_accuracy: 0.3401\n",
      "Epoch 411/3000\n",
      "6/6 [==============================] - 0s 5ms/step - loss: 1.3503 - accuracy: 0.4822 - val_loss: 1.3382 - val_accuracy: 0.4966\n",
      "Epoch 412/3000\n",
      "6/6 [==============================] - 0s 5ms/step - loss: 1.3308 - accuracy: 0.4928 - val_loss: 1.3336 - val_accuracy: 0.4966\n",
      "Epoch 413/3000\n",
      "6/6 [==============================] - 0s 5ms/step - loss: 1.3084 - accuracy: 0.4853 - val_loss: 1.3662 - val_accuracy: 0.4558\n",
      "Epoch 414/3000\n",
      "6/6 [==============================] - 0s 5ms/step - loss: 1.3135 - accuracy: 0.4906 - val_loss: 1.3365 - val_accuracy: 0.4694\n",
      "Epoch 415/3000\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 1.2974 - accuracy: 0.4868 - val_loss: 1.3544 - val_accuracy: 0.4354\n",
      "Epoch 416/3000\n",
      "6/6 [==============================] - 0s 5ms/step - loss: 1.2919 - accuracy: 0.4807 - val_loss: 1.3959 - val_accuracy: 0.4694\n",
      "Epoch 417/3000\n",
      "6/6 [==============================] - 0s 5ms/step - loss: 1.3556 - accuracy: 0.4679 - val_loss: 1.3203 - val_accuracy: 0.5034\n",
      "Epoch 418/3000\n",
      "6/6 [==============================] - 0s 5ms/step - loss: 1.3268 - accuracy: 0.4762 - val_loss: 1.4403 - val_accuracy: 0.4082\n",
      "Epoch 419/3000\n",
      "6/6 [==============================] - 0s 5ms/step - loss: 1.3377 - accuracy: 0.4686 - val_loss: 1.3486 - val_accuracy: 0.4830\n",
      "Epoch 420/3000\n",
      "6/6 [==============================] - 0s 5ms/step - loss: 1.3000 - accuracy: 0.5019 - val_loss: 1.3503 - val_accuracy: 0.4422\n",
      "Epoch 421/3000\n",
      "6/6 [==============================] - 0s 4ms/step - loss: 1.2821 - accuracy: 0.4981 - val_loss: 1.3802 - val_accuracy: 0.4354\n",
      "Epoch 422/3000\n",
      "6/6 [==============================] - 0s 5ms/step - loss: 1.2885 - accuracy: 0.4883 - val_loss: 1.4274 - val_accuracy: 0.4218\n",
      "Epoch 423/3000\n",
      "6/6 [==============================] - 0s 5ms/step - loss: 1.3042 - accuracy: 0.4717 - val_loss: 1.3403 - val_accuracy: 0.4694\n",
      "Epoch 424/3000\n",
      "6/6 [==============================] - 0s 5ms/step - loss: 1.2745 - accuracy: 0.4928 - val_loss: 1.3362 - val_accuracy: 0.4898\n",
      "Epoch 425/3000\n",
      "6/6 [==============================] - 0s 5ms/step - loss: 1.2869 - accuracy: 0.4913 - val_loss: 1.3371 - val_accuracy: 0.5034\n",
      "Epoch 426/3000\n",
      "6/6 [==============================] - 0s 5ms/step - loss: 1.2566 - accuracy: 0.5079 - val_loss: 1.3528 - val_accuracy: 0.4490\n",
      "Epoch 427/3000\n",
      "6/6 [==============================] - 0s 5ms/step - loss: 1.2625 - accuracy: 0.5178 - val_loss: 1.3330 - val_accuracy: 0.5102\n",
      "Epoch 428/3000\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 1.2700 - accuracy: 0.5132 - val_loss: 1.3248 - val_accuracy: 0.5034\n",
      "Epoch 429/3000\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 1.2590 - accuracy: 0.5238 - val_loss: 1.3571 - val_accuracy: 0.4558\n",
      "Epoch 430/3000\n",
      "6/6 [==============================] - 0s 5ms/step - loss: 1.2557 - accuracy: 0.5087 - val_loss: 1.3239 - val_accuracy: 0.4830\n",
      "Epoch 431/3000\n",
      "6/6 [==============================] - 0s 5ms/step - loss: 1.2486 - accuracy: 0.5034 - val_loss: 1.3552 - val_accuracy: 0.4626\n",
      "Epoch 432/3000\n",
      "6/6 [==============================] - 0s 5ms/step - loss: 1.2531 - accuracy: 0.5049 - val_loss: 1.3447 - val_accuracy: 0.5102\n",
      "Epoch 433/3000\n",
      "6/6 [==============================] - 0s 5ms/step - loss: 1.2512 - accuracy: 0.5094 - val_loss: 1.3360 - val_accuracy: 0.5034\n",
      "Epoch 434/3000\n",
      "6/6 [==============================] - 0s 5ms/step - loss: 1.2687 - accuracy: 0.5200 - val_loss: 1.3411 - val_accuracy: 0.4898\n",
      "Epoch 435/3000\n",
      "6/6 [==============================] - 0s 5ms/step - loss: 1.2574 - accuracy: 0.5132 - val_loss: 1.3799 - val_accuracy: 0.4626\n",
      "Epoch 436/3000\n",
      "6/6 [==============================] - 0s 5ms/step - loss: 1.2705 - accuracy: 0.5079 - val_loss: 1.3438 - val_accuracy: 0.4762\n",
      "Epoch 437/3000\n",
      "6/6 [==============================] - 0s 5ms/step - loss: 1.2701 - accuracy: 0.5026 - val_loss: 1.3317 - val_accuracy: 0.4966\n",
      "Epoch 438/3000\n",
      "6/6 [==============================] - 0s 5ms/step - loss: 1.2589 - accuracy: 0.5163 - val_loss: 1.3364 - val_accuracy: 0.5034\n",
      "Epoch 439/3000\n",
      "6/6 [==============================] - 0s 5ms/step - loss: 1.2536 - accuracy: 0.4996 - val_loss: 1.3217 - val_accuracy: 0.4898\n",
      "Epoch 440/3000\n",
      "6/6 [==============================] - 0s 7ms/step - loss: 1.2579 - accuracy: 0.5072 - val_loss: 1.3591 - val_accuracy: 0.4490\n",
      "Epoch 441/3000\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 1.2446 - accuracy: 0.5094 - val_loss: 1.4700 - val_accuracy: 0.4354\n",
      "Epoch 442/3000\n",
      "6/6 [==============================] - 0s 5ms/step - loss: 1.3071 - accuracy: 0.4815 - val_loss: 1.3249 - val_accuracy: 0.5034\n",
      "Epoch 443/3000\n",
      "6/6 [==============================] - 0s 5ms/step - loss: 1.2694 - accuracy: 0.5019 - val_loss: 1.3519 - val_accuracy: 0.4558\n",
      "Epoch 444/3000\n",
      "6/6 [==============================] - 0s 5ms/step - loss: 1.2665 - accuracy: 0.5079 - val_loss: 1.4232 - val_accuracy: 0.4354\n",
      "Epoch 445/3000\n",
      "6/6 [==============================] - 0s 5ms/step - loss: 1.2900 - accuracy: 0.4853 - val_loss: 1.3368 - val_accuracy: 0.4898\n",
      "Epoch 446/3000\n",
      "6/6 [==============================] - 0s 5ms/step - loss: 1.2773 - accuracy: 0.4928 - val_loss: 1.3266 - val_accuracy: 0.4830\n",
      "Epoch 447/3000\n",
      "6/6 [==============================] - 0s 5ms/step - loss: 1.2583 - accuracy: 0.5049 - val_loss: 1.3441 - val_accuracy: 0.5034\n",
      "Epoch 448/3000\n",
      "6/6 [==============================] - 0s 5ms/step - loss: 1.2722 - accuracy: 0.5064 - val_loss: 1.3219 - val_accuracy: 0.4966\n",
      "Epoch 449/3000\n",
      "6/6 [==============================] - 0s 5ms/step - loss: 1.2737 - accuracy: 0.4981 - val_loss: 1.4592 - val_accuracy: 0.4014\n",
      "Epoch 450/3000\n",
      "6/6 [==============================] - 0s 5ms/step - loss: 1.2933 - accuracy: 0.4739 - val_loss: 1.3240 - val_accuracy: 0.5034\n",
      "Epoch 451/3000\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 1.2459 - accuracy: 0.5049 - val_loss: 1.3411 - val_accuracy: 0.5034\n",
      "Epoch 452/3000\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 1.2666 - accuracy: 0.4890 - val_loss: 1.3783 - val_accuracy: 0.4694\n",
      "Epoch 453/3000\n",
      "6/6 [==============================] - 0s 5ms/step - loss: 1.2604 - accuracy: 0.4875 - val_loss: 1.3588 - val_accuracy: 0.5034\n",
      "Epoch 454/3000\n",
      "6/6 [==============================] - 0s 5ms/step - loss: 1.2551 - accuracy: 0.5178 - val_loss: 1.3502 - val_accuracy: 0.4830\n",
      "Epoch 455/3000\n",
      "6/6 [==============================] - 0s 5ms/step - loss: 1.2322 - accuracy: 0.5087 - val_loss: 1.3480 - val_accuracy: 0.4762\n",
      "Epoch 456/3000\n",
      "6/6 [==============================] - 0s 5ms/step - loss: 1.2461 - accuracy: 0.5125 - val_loss: 1.3416 - val_accuracy: 0.4626\n",
      "Epoch 457/3000\n",
      "6/6 [==============================] - 0s 5ms/step - loss: 1.2454 - accuracy: 0.5079 - val_loss: 1.3295 - val_accuracy: 0.4966\n",
      "Epoch 458/3000\n",
      "6/6 [==============================] - 0s 5ms/step - loss: 1.2483 - accuracy: 0.5064 - val_loss: 1.3246 - val_accuracy: 0.5102\n",
      "Epoch 459/3000\n",
      "6/6 [==============================] - 0s 5ms/step - loss: 1.2548 - accuracy: 0.5155 - val_loss: 1.3713 - val_accuracy: 0.4422\n",
      "Epoch 460/3000\n",
      "6/6 [==============================] - 0s 5ms/step - loss: 1.2505 - accuracy: 0.5011 - val_loss: 1.3783 - val_accuracy: 0.4694\n",
      "Epoch 461/3000\n",
      "6/6 [==============================] - 0s 5ms/step - loss: 1.2549 - accuracy: 0.5178 - val_loss: 1.3510 - val_accuracy: 0.4558\n",
      "Epoch 462/3000\n",
      "6/6 [==============================] - 0s 5ms/step - loss: 1.2483 - accuracy: 0.5314 - val_loss: 1.3196 - val_accuracy: 0.5102\n",
      "Epoch 463/3000\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 1.2566 - accuracy: 0.5125 - val_loss: 1.3209 - val_accuracy: 0.5034\n",
      "Epoch 464/3000\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 1.2611 - accuracy: 0.5155 - val_loss: 1.3217 - val_accuracy: 0.5034\n",
      "Epoch 465/3000\n",
      "6/6 [==============================] - 0s 5ms/step - loss: 1.2401 - accuracy: 0.5094 - val_loss: 1.3356 - val_accuracy: 0.4898\n",
      "Epoch 466/3000\n",
      "6/6 [==============================] - 0s 5ms/step - loss: 1.2509 - accuracy: 0.5193 - val_loss: 1.3181 - val_accuracy: 0.5034\n",
      "Epoch 467/3000\n",
      "6/6 [==============================] - 0s 5ms/step - loss: 1.2474 - accuracy: 0.5102 - val_loss: 1.3438 - val_accuracy: 0.4490\n",
      "Epoch 468/3000\n",
      "6/6 [==============================] - 0s 5ms/step - loss: 1.2465 - accuracy: 0.5163 - val_loss: 1.3301 - val_accuracy: 0.4966\n",
      "Epoch 469/3000\n",
      "6/6 [==============================] - 0s 5ms/step - loss: 1.2495 - accuracy: 0.5110 - val_loss: 1.3400 - val_accuracy: 0.4830\n",
      "Epoch 470/3000\n",
      "6/6 [==============================] - 0s 5ms/step - loss: 1.2512 - accuracy: 0.5132 - val_loss: 1.3270 - val_accuracy: 0.4966\n",
      "Epoch 471/3000\n",
      "6/6 [==============================] - 0s 5ms/step - loss: 1.2323 - accuracy: 0.5231 - val_loss: 1.3315 - val_accuracy: 0.5034\n",
      "Epoch 472/3000\n",
      "6/6 [==============================] - 0s 5ms/step - loss: 1.2336 - accuracy: 0.5200 - val_loss: 1.3120 - val_accuracy: 0.5170\n",
      "Epoch 473/3000\n",
      "6/6 [==============================] - 0s 5ms/step - loss: 1.2548 - accuracy: 0.5140 - val_loss: 1.3423 - val_accuracy: 0.4762\n",
      "Epoch 474/3000\n",
      "6/6 [==============================] - 0s 5ms/step - loss: 1.2501 - accuracy: 0.5238 - val_loss: 1.3261 - val_accuracy: 0.5034\n",
      "Epoch 475/3000\n",
      "6/6 [==============================] - 0s 5ms/step - loss: 1.2355 - accuracy: 0.5231 - val_loss: 1.3302 - val_accuracy: 0.5034\n",
      "Epoch 476/3000\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 1.2391 - accuracy: 0.5185 - val_loss: 1.3562 - val_accuracy: 0.4490\n",
      "Epoch 477/3000\n",
      "6/6 [==============================] - 0s 5ms/step - loss: 1.2382 - accuracy: 0.5231 - val_loss: 1.3430 - val_accuracy: 0.5170\n",
      "Epoch 478/3000\n",
      "6/6 [==============================] - 0s 5ms/step - loss: 1.2620 - accuracy: 0.4921 - val_loss: 1.3715 - val_accuracy: 0.4626\n",
      "Epoch 479/3000\n",
      "6/6 [==============================] - 0s 5ms/step - loss: 1.2448 - accuracy: 0.5087 - val_loss: 1.3150 - val_accuracy: 0.4966\n",
      "Epoch 480/3000\n",
      "6/6 [==============================] - 0s 5ms/step - loss: 1.2376 - accuracy: 0.5200 - val_loss: 1.3232 - val_accuracy: 0.5034\n",
      "Epoch 481/3000\n",
      "6/6 [==============================] - 0s 5ms/step - loss: 1.2539 - accuracy: 0.4951 - val_loss: 1.3184 - val_accuracy: 0.4830\n",
      "Epoch 482/3000\n",
      "6/6 [==============================] - 0s 5ms/step - loss: 1.2430 - accuracy: 0.5147 - val_loss: 1.3405 - val_accuracy: 0.4830\n",
      "Epoch 483/3000\n",
      "6/6 [==============================] - 0s 5ms/step - loss: 1.2504 - accuracy: 0.5200 - val_loss: 1.4005 - val_accuracy: 0.4762\n",
      "Epoch 484/3000\n",
      "6/6 [==============================] - 0s 5ms/step - loss: 1.2656 - accuracy: 0.5019 - val_loss: 1.3943 - val_accuracy: 0.4150\n",
      "Epoch 485/3000\n",
      "6/6 [==============================] - 0s 5ms/step - loss: 1.2994 - accuracy: 0.4709 - val_loss: 1.4091 - val_accuracy: 0.4558\n",
      "Epoch 486/3000\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 1.2912 - accuracy: 0.5004 - val_loss: 1.3266 - val_accuracy: 0.5102\n",
      "Epoch 487/3000\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 1.2547 - accuracy: 0.5102 - val_loss: 1.3245 - val_accuracy: 0.5034\n",
      "Epoch 488/3000\n",
      "6/6 [==============================] - 0s 5ms/step - loss: 1.2598 - accuracy: 0.5125 - val_loss: 1.3338 - val_accuracy: 0.4694\n",
      "Epoch 489/3000\n",
      "6/6 [==============================] - 0s 5ms/step - loss: 1.2495 - accuracy: 0.5110 - val_loss: 1.3707 - val_accuracy: 0.4490\n",
      "Epoch 490/3000\n",
      "6/6 [==============================] - 0s 5ms/step - loss: 1.2738 - accuracy: 0.5064 - val_loss: 1.3394 - val_accuracy: 0.4762\n",
      "Epoch 491/3000\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 1.2583 - accuracy: 0.5064 - val_loss: 1.3415 - val_accuracy: 0.4626\n",
      "Epoch 492/3000\n",
      "6/6 [==============================] - 0s 5ms/step - loss: 1.2459 - accuracy: 0.5034 - val_loss: 1.3251 - val_accuracy: 0.5034\n",
      "Epoch 493/3000\n",
      "6/6 [==============================] - 0s 5ms/step - loss: 1.2633 - accuracy: 0.5057 - val_loss: 1.3143 - val_accuracy: 0.4898\n",
      "Epoch 494/3000\n",
      "6/6 [==============================] - 0s 5ms/step - loss: 1.2602 - accuracy: 0.5185 - val_loss: 1.3414 - val_accuracy: 0.4694\n",
      "Epoch 495/3000\n",
      "6/6 [==============================] - 0s 5ms/step - loss: 1.2524 - accuracy: 0.5034 - val_loss: 1.3453 - val_accuracy: 0.4830\n",
      "Epoch 496/3000\n",
      "6/6 [==============================] - 0s 5ms/step - loss: 1.2423 - accuracy: 0.5208 - val_loss: 1.3296 - val_accuracy: 0.4898\n",
      "Epoch 497/3000\n",
      "6/6 [==============================] - 0s 5ms/step - loss: 1.2496 - accuracy: 0.5170 - val_loss: 1.3418 - val_accuracy: 0.4898\n",
      "Epoch 498/3000\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 1.2415 - accuracy: 0.5231 - val_loss: 1.3200 - val_accuracy: 0.4966\n",
      "Epoch 499/3000\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 1.2614 - accuracy: 0.5170 - val_loss: 1.3298 - val_accuracy: 0.4898\n",
      "Epoch 500/3000\n",
      "6/6 [==============================] - 0s 5ms/step - loss: 1.2799 - accuracy: 0.5117 - val_loss: 1.3609 - val_accuracy: 0.4694\n",
      "Epoch 501/3000\n",
      "6/6 [==============================] - 0s 5ms/step - loss: 1.2639 - accuracy: 0.5049 - val_loss: 1.3582 - val_accuracy: 0.4898\n",
      "Epoch 502/3000\n",
      "6/6 [==============================] - 0s 5ms/step - loss: 1.2702 - accuracy: 0.5094 - val_loss: 1.3539 - val_accuracy: 0.4490\n",
      "Epoch 503/3000\n",
      "6/6 [==============================] - 0s 5ms/step - loss: 1.2732 - accuracy: 0.4943 - val_loss: 1.3808 - val_accuracy: 0.4762\n",
      "Epoch 504/3000\n",
      "6/6 [==============================] - 0s 5ms/step - loss: 1.2556 - accuracy: 0.5163 - val_loss: 1.5214 - val_accuracy: 0.4014\n",
      "Epoch 505/3000\n",
      "6/6 [==============================] - 0s 5ms/step - loss: 1.3029 - accuracy: 0.4822 - val_loss: 1.3646 - val_accuracy: 0.4490\n",
      "Epoch 506/3000\n",
      "6/6 [==============================] - 0s 5ms/step - loss: 1.3273 - accuracy: 0.4399 - val_loss: 1.3860 - val_accuracy: 0.4218\n",
      "Epoch 507/3000\n",
      "6/6 [==============================] - 0s 5ms/step - loss: 1.2890 - accuracy: 0.4754 - val_loss: 1.3084 - val_accuracy: 0.5102\n",
      "Epoch 508/3000\n",
      "6/6 [==============================] - 0s 5ms/step - loss: 1.2776 - accuracy: 0.4966 - val_loss: 1.3440 - val_accuracy: 0.4762\n",
      "Epoch 509/3000\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 1.2634 - accuracy: 0.5117 - val_loss: 1.3114 - val_accuracy: 0.4966\n",
      "Epoch 510/3000\n",
      "6/6 [==============================] - 0s 5ms/step - loss: 1.2749 - accuracy: 0.5079 - val_loss: 1.3226 - val_accuracy: 0.5102\n",
      "Epoch 511/3000\n",
      "6/6 [==============================] - 0s 5ms/step - loss: 1.2621 - accuracy: 0.5268 - val_loss: 1.3868 - val_accuracy: 0.4422\n",
      "Epoch 512/3000\n",
      "6/6 [==============================] - 0s 5ms/step - loss: 1.2680 - accuracy: 0.5019 - val_loss: 1.3180 - val_accuracy: 0.5170\n",
      "Epoch 513/3000\n",
      "6/6 [==============================] - 0s 5ms/step - loss: 1.2429 - accuracy: 0.5238 - val_loss: 1.3336 - val_accuracy: 0.4694\n",
      "Epoch 514/3000\n",
      "6/6 [==============================] - 0s 5ms/step - loss: 1.2557 - accuracy: 0.5102 - val_loss: 1.3732 - val_accuracy: 0.4694\n",
      "Epoch 515/3000\n",
      "6/6 [==============================] - 0s 5ms/step - loss: 1.2674 - accuracy: 0.4989 - val_loss: 1.3338 - val_accuracy: 0.4762\n",
      "Epoch 516/3000\n",
      "6/6 [==============================] - 0s 5ms/step - loss: 1.2259 - accuracy: 0.5193 - val_loss: 1.3528 - val_accuracy: 0.4626\n",
      "Epoch 517/3000\n",
      "6/6 [==============================] - 0s 5ms/step - loss: 1.2396 - accuracy: 0.5110 - val_loss: 1.3267 - val_accuracy: 0.4694\n",
      "Epoch 518/3000\n",
      "6/6 [==============================] - 0s 5ms/step - loss: 1.2601 - accuracy: 0.5223 - val_loss: 1.3380 - val_accuracy: 0.4626\n",
      "Epoch 519/3000\n",
      "6/6 [==============================] - 0s 5ms/step - loss: 1.2479 - accuracy: 0.5246 - val_loss: 1.3190 - val_accuracy: 0.4762\n",
      "Epoch 520/3000\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 1.2455 - accuracy: 0.5140 - val_loss: 1.3129 - val_accuracy: 0.4830\n",
      "Epoch 521/3000\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 1.2216 - accuracy: 0.5163 - val_loss: 1.3539 - val_accuracy: 0.4490\n",
      "Epoch 522/3000\n",
      "6/6 [==============================] - 0s 5ms/step - loss: 1.2288 - accuracy: 0.5200 - val_loss: 1.4074 - val_accuracy: 0.4558\n",
      "Epoch 523/3000\n",
      "6/6 [==============================] - 0s 5ms/step - loss: 1.2782 - accuracy: 0.5034 - val_loss: 1.3559 - val_accuracy: 0.4558\n",
      "Epoch 524/3000\n",
      "6/6 [==============================] - 0s 5ms/step - loss: 1.2363 - accuracy: 0.5223 - val_loss: 1.3219 - val_accuracy: 0.4830\n",
      "Epoch 525/3000\n",
      "6/6 [==============================] - 0s 5ms/step - loss: 1.2391 - accuracy: 0.5094 - val_loss: 1.3148 - val_accuracy: 0.5034\n",
      "Epoch 526/3000\n",
      "6/6 [==============================] - 0s 5ms/step - loss: 1.2392 - accuracy: 0.5178 - val_loss: 1.3932 - val_accuracy: 0.4626\n",
      "Epoch 527/3000\n",
      "6/6 [==============================] - 0s 5ms/step - loss: 1.2692 - accuracy: 0.5026 - val_loss: 1.3385 - val_accuracy: 0.4966\n",
      "Epoch 528/3000\n",
      "6/6 [==============================] - 0s 5ms/step - loss: 1.2449 - accuracy: 0.5276 - val_loss: 1.3183 - val_accuracy: 0.4898\n",
      "Epoch 529/3000\n",
      "6/6 [==============================] - 0s 5ms/step - loss: 1.2517 - accuracy: 0.5147 - val_loss: 1.3180 - val_accuracy: 0.4898\n",
      "Epoch 530/3000\n",
      "6/6 [==============================] - 0s 5ms/step - loss: 1.2449 - accuracy: 0.5246 - val_loss: 1.3544 - val_accuracy: 0.4558\n",
      "Epoch 531/3000\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 1.2496 - accuracy: 0.5117 - val_loss: 1.3401 - val_accuracy: 0.5102\n",
      "Epoch 532/3000\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 1.2480 - accuracy: 0.5238 - val_loss: 1.3514 - val_accuracy: 0.4830\n",
      "Epoch 533/3000\n",
      "6/6 [==============================] - 0s 5ms/step - loss: 1.2627 - accuracy: 0.5049 - val_loss: 1.3166 - val_accuracy: 0.5034\n",
      "Epoch 534/3000\n",
      "6/6 [==============================] - 0s 5ms/step - loss: 1.2556 - accuracy: 0.5110 - val_loss: 1.3332 - val_accuracy: 0.4898\n",
      "Epoch 535/3000\n",
      "6/6 [==============================] - 0s 5ms/step - loss: 1.2519 - accuracy: 0.5185 - val_loss: 1.3636 - val_accuracy: 0.4354\n",
      "Epoch 536/3000\n",
      "6/6 [==============================] - 0s 5ms/step - loss: 1.2402 - accuracy: 0.5163 - val_loss: 1.3180 - val_accuracy: 0.5102\n",
      "Epoch 537/3000\n",
      "1/6 [====>.........................] - ETA: 0s - loss: 1.2838 - accuracy: 0.5195Restoring model weights from the end of the best epoch: 337.\n",
      "6/6 [==============================] - 0s 5ms/step - loss: 1.2362 - accuracy: 0.5276 - val_loss: 1.3563 - val_accuracy: 0.4558\n",
      "Epoch 537: early stopping\n"
     ]
    }
   ],
   "source": [
    "training_history = model.fit(\n",
    "    features[\"train\"],\n",
    "    y_train,\n",
    "    epochs=EPOCHS,\n",
    "    validation_split=0.1,\n",
    "    batch_size=BATCH_SIZE,\n",
    "    callbacks=[early_stopping]\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: /home/fernandofincatti/.cascid_data/experiments/fernando/models/deep_learning/assets\n"
     ]
    }
   ],
   "source": [
    "model.save(MODEL_PATH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(MODEL_PATH / 'history.pkl', 'wb') as fl:\n",
    "    pickle.dump(training_history.history, fl)\n",
    "training_history = training_history.history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "15/15 [==============================] - 0s 1ms/step - loss: 1.3240 - accuracy: 0.4913\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[1.3240433931350708, 0.49130433797836304]"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.evaluate(x=x_test, y=y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_confusion_matrix(y_true, y_pred, classes,\n",
    "                          normalize=True,\n",
    "                          title=None,\n",
    "                          cmap=plt.cm.Greens, save_to_file = False):\n",
    "    if not title:\n",
    "        if normalize:\n",
    "            title = 'Normalized confusion matrix'\n",
    "        else:\n",
    "            title = 'Confusion matrix, without normalization'\n",
    "\n",
    "    # Compute confusion matrix\n",
    "    cm = confusion_matrix(y_true, y_pred)\n",
    "    if normalize:\n",
    "        cm = cm.astype('float') / cm.sum(axis=1)[:, np.newaxis]\n",
    "        #print(\"Normalized confusion matrix\")\n",
    "    else:\n",
    "        print('Confusion matrix, without normalization')\n",
    "\n",
    "    #print(cm)\n",
    "\n",
    "    fig, ax = plt.subplots(figsize = (16,16))\n",
    "    im = ax.imshow(cm, interpolation='nearest', cmap=cmap)\n",
    "    ax.figure.colorbar(im, ax=ax)\n",
    "    ax.set(xticks=np.arange(cm.shape[1]),\n",
    "           yticks=np.arange(cm.shape[0]),\n",
    "           xticklabels=classes, yticklabels=classes,\n",
    "           title=title,\n",
    "           ylabel='True label',\n",
    "           xlabel='Predicted label')\n",
    "\n",
    "    plt.setp(ax.get_xticklabels(), rotation=45, ha=\"right\",\n",
    "             rotation_mode=\"anchor\")\n",
    "\n",
    "    fmt = '.2f' if normalize else 'd'\n",
    "    thresh = cm.max() / 2.\n",
    "    for i in range(cm.shape[0]):\n",
    "        for j in range(cm.shape[1]):\n",
    "            ax.text(j, i, format(cm[i, j], fmt),\n",
    "                    ha=\"center\", va=\"center\",\n",
    "                    color=\"white\" if cm[i, j] > thresh else \"black\")\n",
    "    fig.tight_layout()\n",
    "    if save_to_file:\n",
    "        plt.savefig('Assets/files/' + title + '.pdf')\n",
    "    return ax"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.4 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "916dbcbb3f70747c44a77c7bcd40155683ae19c65e1c03b4aa3499c5328201f1"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
