{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### BINARY CLASSIFIER: PAD-UFES\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-10-07 17:33:25.877943: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2022-10-07 17:33:26.187603: E tensorflow/stream_executor/cuda/cuda_blas.cc:2981] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "2022-10-07 17:33:26.994835: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer.so.7'; dlerror: libnvinfer.so.7: cannot open shared object file: No such file or directory\n",
      "2022-10-07 17:33:26.994903: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libnvinfer_plugin.so.7: cannot open shared object file: No such file or directory\n",
      "2022-10-07 17:33:26.994908: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.\n"
     ]
    }
   ],
   "source": [
    "#basic\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "#keras\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras.layers import \\\n",
    "    Input, Dense, Conv2D, GlobalAveragePooling2D, Flatten,\\\n",
    "    MaxPooling2D, Dropout, Resizing, Rescaling, RandomContrast,\\\n",
    "    RandomCrop, RandomFlip, RandomRotation, BatchNormalization\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.utils import load_img, img_to_array\n",
    "\n",
    "#sklearn\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "#cascid\n",
    "from cascid.configs import config, pad_ufes\n",
    "from cascid import database\n",
    "\n",
    "#utils\n",
    "from utils import transform_diagnose_to_binary, read_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-10-07 17:33:28.340166: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:980] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-10-07 17:33:28.370845: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:980] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-10-07 17:33:28.371033: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:980] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n"
     ]
    }
   ],
   "source": [
    "gpus = tf.config.experimental.list_physical_devices('GPU')\n",
    "tf.config.experimental.set_memory_growth(gpus[0], True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Setting paths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "FERNANDO_PATH = config.DATA_DIR / 'experiments' / 'fernando'\n",
    "FERNANDO_PATH.mkdir(exist_ok=True, parents=True)\n",
    "\n",
    "IMAGE_CACHE = FERNANDO_PATH / 'img_cache.pkl'\n",
    "FEATURES_FILE = FERNANDO_PATH / 'features.pkl'\n",
    "MODEL_PATH = FERNANDO_PATH / 'models' / 'deep_learning'\n",
    "\n",
    "IMDIR = pad_ufes.IMAGES_DIR"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Globals"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "RANDOM_STATE = 42\n",
    "TRAIN_SIZE = 0.7\n",
    "VALIDATION_SIZE = 0.15\n",
    "TEST_SIZE = 0.15\n",
    "EPOCHS = 3000\n",
    "IMAGE_SHAPE = (64, 64, 3)\n",
    "IMAGES_ON_GPG = 64\n",
    "BATCH_SIZE = 32"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Get images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "pad_ufes_df = read_data(image_shape=IMAGE_SHAPE)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Change to binary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "diagnose_to_binary_dict = {\n",
    "    \"BCC\": 1, \"SCC\": 1, \"MEL\": 1,\n",
    "    \"ACK\": 0, \"NEV\": 0, \"SEK\": 0}\n",
    "dataframe_to_binary = pad_ufes_df.copy()\n",
    "dataframe_to_binary[\"diagnostic_binary\"] = dataframe_to_binary[\"diagnostic\"].apply(lambda diagnostic: \n",
    "    transform_diagnose_to_binary(diagnostic, diagnose_to_binary_dict))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['patient_id', 'lesion_id', 'smoke', 'drink', 'background_father',\n",
       "       'background_mother', 'age', 'pesticide', 'gender',\n",
       "       'skin_cancer_history', 'cancer_history', 'has_piped_water',\n",
       "       'has_sewage_system', 'fitspatrick', 'region', 'diameter_1',\n",
       "       'diameter_2', 'diagnostic', 'itch', 'grew', 'hurt', 'changed', 'bleed',\n",
       "       'elevation', 'img_id', 'biopsed', 'image_array', 'diagnostic_binary'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataframe_to_binary.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "filtered_df = dataframe_to_binary[[\"image_array\",\"diagnostic_binary\"]].copy()\n",
    "filtered_df.rename(columns = {\"image_array\":\"x\", \"diagnostic_binary\": \"y\"}, inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>x</th>\n",
       "      <th>y</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>[[[0.7058823529411765, 0.6, 0.5176470588235295...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>[[[0.8235294117647058, 0.6745098039215687, 0.6...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>[[[0.592156862745098, 0.34901960784313724, 0.2...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>[[[0.8784313725490196, 0.7333333333333333, 0.6...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>[[[0.7058823529411765, 0.49019607843137253, 0....</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                   x  y\n",
       "0  [[[0.7058823529411765, 0.6, 0.5176470588235295...  0\n",
       "1  [[[0.8235294117647058, 0.6745098039215687, 0.6...  1\n",
       "2  [[[0.592156862745098, 0.34901960784313724, 0.2...  0\n",
       "3  [[[0.8784313725490196, 0.7333333333333333, 0.6...  0\n",
       "4  [[[0.7058823529411765, 0.49019607843137253, 0....  0"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "filtered_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train and test split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(filtered_df[\"x\"], filtered_df[\"y\"], test_size=0.2, random_state=42)\n",
    "X_train, X_val, y_train, y_val = train_test_split(X_train, y_train, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Transform to tensor data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-10-07 17:34:23.048022: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2022-10-07 17:34:23.049004: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:980] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-10-07 17:34:23.049217: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:980] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-10-07 17:34:23.049330: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:980] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-10-07 17:34:23.636403: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:980] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-10-07 17:34:23.636751: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:980] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-10-07 17:34:23.636862: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:980] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-10-07 17:34:23.636949: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1616] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 4091 MB memory:  -> device: 0, name: NVIDIA GeForce RTX 2060, pci bus id: 0000:01:00.0, compute capability: 7.5\n"
     ]
    }
   ],
   "source": [
    "with tf.device(\"/GPU:0\"):\n",
    "    x = tf.constant(filtered_df[\"x\"].tolist())\n",
    "    y = tf.constant(filtered_df[\"y\"].tolist())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Building model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Using a while_loop for converting RngReadAndSkip cause there is no registered converter for this op.\n",
      "WARNING:tensorflow:Using a while_loop for converting Bitcast cause there is no registered converter for this op.\n",
      "WARNING:tensorflow:Using a while_loop for converting Bitcast cause there is no registered converter for this op.\n",
      "WARNING:tensorflow:Using a while_loop for converting StatelessRandomUniformFullIntV2 cause there is no registered converter for this op.\n",
      "WARNING:tensorflow:Using a while_loop for converting StatelessRandomGetKeyCounter cause there is no registered converter for this op.\n",
      "WARNING:tensorflow:Using a while_loop for converting StatelessRandomUniformV2 cause there is no registered converter for this op.\n",
      "WARNING:tensorflow:Using a while_loop for converting AdjustContrastv2 cause Input \"contrast_factor\" of op 'AdjustContrastv2' expected to be loop invariant.\n",
      "WARNING:tensorflow:Using a while_loop for converting RngReadAndSkip cause there is no registered converter for this op.\n",
      "WARNING:tensorflow:Using a while_loop for converting Bitcast cause there is no registered converter for this op.\n",
      "WARNING:tensorflow:Using a while_loop for converting Bitcast cause there is no registered converter for this op.\n",
      "WARNING:tensorflow:Using a while_loop for converting StatelessRandomUniformV2 cause there is no registered converter for this op.\n",
      "WARNING:tensorflow:Using a while_loop for converting ImageProjectiveTransformV3 cause there is no registered converter for this op.\n"
     ]
    }
   ],
   "source": [
    "input_shape = IMAGE_SHAPE\n",
    "model = Sequential(\n",
    "    [\n",
    "        Input(input_shape),\n",
    "        RandomContrast(factor=0.3,seed=RANDOM_STATE),\n",
    "        RandomFlip(mode=\"horizontal_and_vertical\",seed=RANDOM_STATE),\n",
    "        RandomRotation(factor=(-0.3, 0.3), fill_mode=\"nearest\", interpolation=\"bilinear\", seed=RANDOM_STATE),    \n",
    "        Conv2D(64, kernel_size=(7, 7), activation='relu', name=\"TopConv1\"),\n",
    "        Conv2D(64, kernel_size=(7, 7), activation='relu', name=\"TopConv2\"),\n",
    "        BatchNormalization(),\n",
    "        MaxPooling2D(pool_size=(2, 2), name=\"TopBatchNorm\"),\n",
    "        Conv2D(32, kernel_size=(5, 5), activation='relu', name=\"CenterConv1\"),\n",
    "        Conv2D(32, kernel_size=(5, 5), activation='relu', name=\"CenterConv2\"),\n",
    "        BatchNormalization(),\n",
    "        MaxPooling2D(pool_size=(2, 2), name=\"CenterBatchNorm\"),\n",
    "        Conv2D(16, kernel_size=(3, 3), activation='relu', name=\"BottomConv1\"),\n",
    "        Conv2D(16, kernel_size=(3, 3), activation='relu', name=\"BottomConv2\"),\n",
    "        BatchNormalization(),\n",
    "        MaxPooling2D(pool_size=(2, 2), name=\"BottomBatchNorm\"),\n",
    "        Flatten(),\n",
    "        Dense(128, activation='relu'),\n",
    "        Dense(64, activation='relu'),\n",
    "        Dense(32),\n",
    "        Dropout(0.2),\n",
    "        Dense(32),\n",
    "        Dense(1, activation='sigmoid'),\n",
    "    ]\n",
    " )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(\n",
    "    optimizer='adam',\n",
    "    loss=keras.losses.BinaryCrossentropy(),\n",
    "    metrics=[\"accuracy\"])   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "es = EarlyStopping(\n",
    "    monitor='val_loss',\n",
    "    mode='min',\n",
    "    verbose=1,\n",
    "    patience=30,\n",
    "    restore_best_weights=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/1000\n",
      "58/58 [==============================] - 5s 82ms/step - loss: 0.6656 - accuracy: 0.6094 - val_loss: 0.7069 - val_accuracy: 0.4457\n",
      "Epoch 2/1000\n",
      "58/58 [==============================] - 5s 78ms/step - loss: 0.6213 - accuracy: 0.6561 - val_loss: 1.7580 - val_accuracy: 0.4326\n",
      "Epoch 3/1000\n",
      "58/58 [==============================] - 4s 77ms/step - loss: 0.6048 - accuracy: 0.6817 - val_loss: 0.5890 - val_accuracy: 0.7000\n",
      "Epoch 4/1000\n",
      "58/58 [==============================] - 5s 80ms/step - loss: 0.5891 - accuracy: 0.6986 - val_loss: 0.5765 - val_accuracy: 0.7109\n",
      "Epoch 5/1000\n",
      "58/58 [==============================] - 5s 83ms/step - loss: 0.5829 - accuracy: 0.6970 - val_loss: 0.5612 - val_accuracy: 0.7261\n",
      "Epoch 6/1000\n",
      "58/58 [==============================] - 5s 83ms/step - loss: 0.5855 - accuracy: 0.6964 - val_loss: 0.6436 - val_accuracy: 0.6848\n",
      "Epoch 7/1000\n",
      "58/58 [==============================] - 4s 77ms/step - loss: 0.5759 - accuracy: 0.7122 - val_loss: 0.6722 - val_accuracy: 0.5478\n",
      "Epoch 8/1000\n",
      "58/58 [==============================] - 4s 77ms/step - loss: 0.5875 - accuracy: 0.6866 - val_loss: 0.5767 - val_accuracy: 0.6761\n",
      "Epoch 9/1000\n",
      "58/58 [==============================] - 5s 79ms/step - loss: 0.5665 - accuracy: 0.7040 - val_loss: 0.7151 - val_accuracy: 0.6587\n",
      "Epoch 10/1000\n",
      "58/58 [==============================] - 4s 78ms/step - loss: 0.5670 - accuracy: 0.6948 - val_loss: 0.7382 - val_accuracy: 0.6109\n",
      "Epoch 11/1000\n",
      "58/58 [==============================] - 4s 77ms/step - loss: 0.5715 - accuracy: 0.7155 - val_loss: 0.8606 - val_accuracy: 0.6087\n",
      "Epoch 12/1000\n",
      "58/58 [==============================] - 4s 78ms/step - loss: 0.5646 - accuracy: 0.6997 - val_loss: 0.6756 - val_accuracy: 0.6043\n",
      "Epoch 13/1000\n",
      "58/58 [==============================] - 5s 78ms/step - loss: 0.5601 - accuracy: 0.7155 - val_loss: 0.8192 - val_accuracy: 0.5457\n",
      "Epoch 14/1000\n",
      "58/58 [==============================] - 5s 78ms/step - loss: 0.5594 - accuracy: 0.7182 - val_loss: 0.6108 - val_accuracy: 0.6587\n",
      "Epoch 15/1000\n",
      "58/58 [==============================] - 5s 82ms/step - loss: 0.5524 - accuracy: 0.7323 - val_loss: 1.9745 - val_accuracy: 0.5696\n",
      "Epoch 16/1000\n",
      "58/58 [==============================] - 5s 79ms/step - loss: 0.5735 - accuracy: 0.7018 - val_loss: 0.5551 - val_accuracy: 0.7348\n",
      "Epoch 17/1000\n",
      "58/58 [==============================] - 13s 228ms/step - loss: 0.5581 - accuracy: 0.7193 - val_loss: 0.7904 - val_accuracy: 0.5152\n",
      "Epoch 18/1000\n",
      "58/58 [==============================] - 23s 399ms/step - loss: 0.5549 - accuracy: 0.7100 - val_loss: 0.6061 - val_accuracy: 0.7087\n",
      "Epoch 19/1000\n",
      "58/58 [==============================] - 19s 319ms/step - loss: 0.5467 - accuracy: 0.7209 - val_loss: 0.5699 - val_accuracy: 0.7239\n",
      "Epoch 20/1000\n",
      "58/58 [==============================] - 7s 122ms/step - loss: 0.5464 - accuracy: 0.7252 - val_loss: 0.5080 - val_accuracy: 0.7478\n",
      "Epoch 21/1000\n",
      "58/58 [==============================] - 6s 109ms/step - loss: 0.5470 - accuracy: 0.7236 - val_loss: 0.5242 - val_accuracy: 0.7196\n",
      "Epoch 22/1000\n",
      "58/58 [==============================] - 6s 100ms/step - loss: 0.5417 - accuracy: 0.7242 - val_loss: 0.5256 - val_accuracy: 0.7587\n",
      "Epoch 23/1000\n",
      "58/58 [==============================] - 6s 95ms/step - loss: 0.5412 - accuracy: 0.7280 - val_loss: 0.7194 - val_accuracy: 0.5283\n",
      "Epoch 24/1000\n",
      "58/58 [==============================] - 5s 93ms/step - loss: 0.5430 - accuracy: 0.7318 - val_loss: 0.6105 - val_accuracy: 0.6674\n",
      "Epoch 25/1000\n",
      "58/58 [==============================] - 5s 91ms/step - loss: 0.5355 - accuracy: 0.7198 - val_loss: 0.5034 - val_accuracy: 0.7630\n",
      "Epoch 26/1000\n",
      "58/58 [==============================] - 5s 87ms/step - loss: 0.5398 - accuracy: 0.7339 - val_loss: 0.5688 - val_accuracy: 0.7000\n",
      "Epoch 27/1000\n",
      "58/58 [==============================] - 5s 84ms/step - loss: 0.5444 - accuracy: 0.7214 - val_loss: 0.7368 - val_accuracy: 0.6435\n",
      "Epoch 28/1000\n",
      "58/58 [==============================] - 5s 85ms/step - loss: 0.5367 - accuracy: 0.7323 - val_loss: 0.5959 - val_accuracy: 0.6891\n",
      "Epoch 29/1000\n",
      "58/58 [==============================] - 5s 84ms/step - loss: 0.5285 - accuracy: 0.7318 - val_loss: 0.7765 - val_accuracy: 0.5087\n",
      "Epoch 30/1000\n",
      "58/58 [==============================] - 5s 83ms/step - loss: 0.5413 - accuracy: 0.7258 - val_loss: 0.5603 - val_accuracy: 0.6935\n",
      "Epoch 31/1000\n",
      "58/58 [==============================] - 5s 82ms/step - loss: 0.5339 - accuracy: 0.7356 - val_loss: 0.5417 - val_accuracy: 0.7435\n",
      "Epoch 32/1000\n",
      "58/58 [==============================] - 5s 80ms/step - loss: 0.5245 - accuracy: 0.7388 - val_loss: 0.6665 - val_accuracy: 0.5978\n",
      "Epoch 33/1000\n",
      "58/58 [==============================] - 5s 84ms/step - loss: 0.5229 - accuracy: 0.7345 - val_loss: 0.8299 - val_accuracy: 0.6500\n",
      "Epoch 34/1000\n",
      "58/58 [==============================] - 5s 87ms/step - loss: 0.5216 - accuracy: 0.7367 - val_loss: 0.8217 - val_accuracy: 0.4739\n",
      "Epoch 35/1000\n",
      "58/58 [==============================] - 9s 155ms/step - loss: 0.5272 - accuracy: 0.7394 - val_loss: 0.4877 - val_accuracy: 0.7609\n",
      "Epoch 36/1000\n",
      "58/58 [==============================] - 25s 426ms/step - loss: 0.5189 - accuracy: 0.7416 - val_loss: 0.5525 - val_accuracy: 0.7109\n",
      "Epoch 37/1000\n",
      "58/58 [==============================] - 19s 321ms/step - loss: 0.5288 - accuracy: 0.7388 - val_loss: 0.5104 - val_accuracy: 0.7522\n",
      "Epoch 38/1000\n",
      "58/58 [==============================] - 7s 115ms/step - loss: 0.5173 - accuracy: 0.7448 - val_loss: 0.5665 - val_accuracy: 0.7000\n",
      "Epoch 39/1000\n",
      "58/58 [==============================] - 6s 104ms/step - loss: 0.5172 - accuracy: 0.7497 - val_loss: 0.4940 - val_accuracy: 0.7783\n",
      "Epoch 40/1000\n",
      "58/58 [==============================] - 6s 100ms/step - loss: 0.5020 - accuracy: 0.7601 - val_loss: 0.4987 - val_accuracy: 0.7696\n",
      "Epoch 41/1000\n",
      "58/58 [==============================] - 6s 98ms/step - loss: 0.5143 - accuracy: 0.7410 - val_loss: 0.5079 - val_accuracy: 0.7435\n",
      "Epoch 42/1000\n",
      "58/58 [==============================] - 5s 93ms/step - loss: 0.5128 - accuracy: 0.7410 - val_loss: 0.4979 - val_accuracy: 0.7609\n",
      "Epoch 43/1000\n",
      "58/58 [==============================] - 6s 97ms/step - loss: 0.4979 - accuracy: 0.7535 - val_loss: 0.5259 - val_accuracy: 0.7500\n",
      "Epoch 44/1000\n",
      "58/58 [==============================] - 5s 92ms/step - loss: 0.5062 - accuracy: 0.7470 - val_loss: 0.6104 - val_accuracy: 0.7152\n",
      "Epoch 45/1000\n",
      "58/58 [==============================] - 5s 89ms/step - loss: 0.5102 - accuracy: 0.7448 - val_loss: 0.5608 - val_accuracy: 0.7087\n",
      "Epoch 46/1000\n",
      "58/58 [==============================] - 5s 87ms/step - loss: 0.5068 - accuracy: 0.7590 - val_loss: 0.5352 - val_accuracy: 0.7391\n",
      "Epoch 47/1000\n",
      "58/58 [==============================] - 5s 88ms/step - loss: 0.5146 - accuracy: 0.7503 - val_loss: 0.5266 - val_accuracy: 0.7370\n",
      "Epoch 48/1000\n",
      "58/58 [==============================] - 5s 85ms/step - loss: 0.5177 - accuracy: 0.7437 - val_loss: 0.5099 - val_accuracy: 0.7478\n",
      "Epoch 49/1000\n",
      "58/58 [==============================] - 5s 82ms/step - loss: 0.4943 - accuracy: 0.7644 - val_loss: 0.5158 - val_accuracy: 0.7370\n",
      "Epoch 50/1000\n",
      "58/58 [==============================] - 5s 78ms/step - loss: 0.4919 - accuracy: 0.7579 - val_loss: 0.4955 - val_accuracy: 0.7630\n",
      "Epoch 51/1000\n",
      "58/58 [==============================] - 5s 79ms/step - loss: 0.5013 - accuracy: 0.7497 - val_loss: 0.5695 - val_accuracy: 0.7043\n",
      "Epoch 52/1000\n",
      "58/58 [==============================] - 5s 81ms/step - loss: 0.4970 - accuracy: 0.7628 - val_loss: 0.5849 - val_accuracy: 0.7174\n",
      "Epoch 53/1000\n",
      "58/58 [==============================] - 5s 95ms/step - loss: 0.4917 - accuracy: 0.7791 - val_loss: 0.4968 - val_accuracy: 0.7587\n",
      "Epoch 54/1000\n",
      "58/58 [==============================] - 20s 350ms/step - loss: 0.4950 - accuracy: 0.7628 - val_loss: 0.4970 - val_accuracy: 0.7543\n",
      "Epoch 55/1000\n",
      "58/58 [==============================] - 21s 361ms/step - loss: 0.5033 - accuracy: 0.7622 - val_loss: 0.5229 - val_accuracy: 0.7370\n",
      "Epoch 56/1000\n",
      "58/58 [==============================] - 12s 197ms/step - loss: 0.4968 - accuracy: 0.7633 - val_loss: 0.4929 - val_accuracy: 0.7696\n",
      "Epoch 57/1000\n",
      "58/58 [==============================] - 6s 110ms/step - loss: 0.4853 - accuracy: 0.7671 - val_loss: 0.6200 - val_accuracy: 0.7174\n",
      "Epoch 58/1000\n",
      "58/58 [==============================] - 6s 99ms/step - loss: 0.4850 - accuracy: 0.7682 - val_loss: 0.4916 - val_accuracy: 0.7717\n",
      "Epoch 59/1000\n",
      "58/58 [==============================] - 5s 94ms/step - loss: 0.4989 - accuracy: 0.7720 - val_loss: 0.5109 - val_accuracy: 0.7587\n",
      "Epoch 60/1000\n",
      "58/58 [==============================] - 5s 89ms/step - loss: 0.4814 - accuracy: 0.7813 - val_loss: 0.4811 - val_accuracy: 0.7696\n",
      "Epoch 61/1000\n",
      "58/58 [==============================] - 5s 87ms/step - loss: 0.4844 - accuracy: 0.7617 - val_loss: 0.4818 - val_accuracy: 0.7848\n",
      "Epoch 62/1000\n",
      "58/58 [==============================] - 5s 86ms/step - loss: 0.5012 - accuracy: 0.7622 - val_loss: 0.4980 - val_accuracy: 0.7674\n",
      "Epoch 63/1000\n",
      "58/58 [==============================] - 5s 83ms/step - loss: 0.4789 - accuracy: 0.7704 - val_loss: 0.4871 - val_accuracy: 0.7783\n",
      "Epoch 64/1000\n",
      "58/58 [==============================] - 5s 85ms/step - loss: 0.4834 - accuracy: 0.7655 - val_loss: 0.5464 - val_accuracy: 0.7326\n",
      "Epoch 65/1000\n",
      "58/58 [==============================] - 5s 82ms/step - loss: 0.4745 - accuracy: 0.7666 - val_loss: 0.5231 - val_accuracy: 0.7457\n",
      "Epoch 66/1000\n",
      "58/58 [==============================] - 5s 79ms/step - loss: 0.4704 - accuracy: 0.7726 - val_loss: 0.5045 - val_accuracy: 0.7174\n",
      "Epoch 67/1000\n",
      "58/58 [==============================] - 5s 78ms/step - loss: 0.4799 - accuracy: 0.7726 - val_loss: 0.6659 - val_accuracy: 0.6435\n",
      "Epoch 68/1000\n",
      "58/58 [==============================] - 4s 77ms/step - loss: 0.4869 - accuracy: 0.7606 - val_loss: 0.5404 - val_accuracy: 0.7674\n",
      "Epoch 69/1000\n",
      "58/58 [==============================] - 4s 76ms/step - loss: 0.4819 - accuracy: 0.7780 - val_loss: 0.4899 - val_accuracy: 0.7761\n",
      "Epoch 70/1000\n",
      "58/58 [==============================] - 4s 75ms/step - loss: 0.4641 - accuracy: 0.7889 - val_loss: 0.4812 - val_accuracy: 0.7891\n",
      "Epoch 71/1000\n",
      "58/58 [==============================] - 4s 76ms/step - loss: 0.4633 - accuracy: 0.7764 - val_loss: 0.5083 - val_accuracy: 0.7522\n",
      "Epoch 72/1000\n",
      "58/58 [==============================] - 4s 77ms/step - loss: 0.4663 - accuracy: 0.7797 - val_loss: 0.5626 - val_accuracy: 0.7087\n",
      "Epoch 73/1000\n",
      "58/58 [==============================] - 5s 82ms/step - loss: 0.4818 - accuracy: 0.7769 - val_loss: 0.4977 - val_accuracy: 0.7522\n",
      "Epoch 74/1000\n",
      "58/58 [==============================] - 13s 233ms/step - loss: 0.4736 - accuracy: 0.7856 - val_loss: 0.4884 - val_accuracy: 0.7826\n",
      "Epoch 75/1000\n",
      "58/58 [==============================] - 21s 357ms/step - loss: 0.4488 - accuracy: 0.7845 - val_loss: 0.5721 - val_accuracy: 0.7261\n",
      "Epoch 76/1000\n",
      "58/58 [==============================] - 15s 253ms/step - loss: 0.4681 - accuracy: 0.7726 - val_loss: 0.4777 - val_accuracy: 0.7870\n",
      "Epoch 77/1000\n",
      "58/58 [==============================] - 6s 111ms/step - loss: 0.4492 - accuracy: 0.7933 - val_loss: 0.5781 - val_accuracy: 0.7217\n",
      "Epoch 78/1000\n",
      "58/58 [==============================] - 6s 102ms/step - loss: 0.4775 - accuracy: 0.7753 - val_loss: 0.4864 - val_accuracy: 0.7696\n",
      "Epoch 79/1000\n",
      "58/58 [==============================] - 6s 97ms/step - loss: 0.4655 - accuracy: 0.7829 - val_loss: 0.4680 - val_accuracy: 0.7804\n",
      "Epoch 80/1000\n",
      "58/58 [==============================] - 5s 91ms/step - loss: 0.4677 - accuracy: 0.7780 - val_loss: 0.5185 - val_accuracy: 0.7326\n",
      "Epoch 81/1000\n",
      "58/58 [==============================] - 5s 87ms/step - loss: 0.4474 - accuracy: 0.7900 - val_loss: 0.4836 - val_accuracy: 0.8065\n",
      "Epoch 82/1000\n",
      "58/58 [==============================] - 5s 86ms/step - loss: 0.4392 - accuracy: 0.7938 - val_loss: 0.4922 - val_accuracy: 0.7761\n",
      "Epoch 83/1000\n",
      "58/58 [==============================] - 5s 84ms/step - loss: 0.4501 - accuracy: 0.7911 - val_loss: 0.5243 - val_accuracy: 0.7478\n",
      "Epoch 84/1000\n",
      "58/58 [==============================] - 5s 82ms/step - loss: 0.4464 - accuracy: 0.7878 - val_loss: 0.7047 - val_accuracy: 0.7391\n",
      "Epoch 85/1000\n",
      "58/58 [==============================] - 5s 81ms/step - loss: 0.4406 - accuracy: 0.7927 - val_loss: 0.5270 - val_accuracy: 0.7630\n",
      "Epoch 86/1000\n",
      "58/58 [==============================] - 5s 80ms/step - loss: 0.4499 - accuracy: 0.7949 - val_loss: 0.4865 - val_accuracy: 0.7783\n",
      "Epoch 87/1000\n",
      "58/58 [==============================] - 5s 78ms/step - loss: 0.4581 - accuracy: 0.7927 - val_loss: 0.4831 - val_accuracy: 0.7848\n",
      "Epoch 88/1000\n",
      "58/58 [==============================] - 4s 77ms/step - loss: 0.4568 - accuracy: 0.7916 - val_loss: 0.4841 - val_accuracy: 0.7848\n",
      "Epoch 89/1000\n",
      "58/58 [==============================] - 4s 77ms/step - loss: 0.4443 - accuracy: 0.7998 - val_loss: 0.4885 - val_accuracy: 0.7630\n",
      "Epoch 90/1000\n",
      "58/58 [==============================] - 4s 76ms/step - loss: 0.4387 - accuracy: 0.7905 - val_loss: 0.5688 - val_accuracy: 0.7457\n",
      "Epoch 91/1000\n",
      "58/58 [==============================] - 4s 77ms/step - loss: 0.4431 - accuracy: 0.7911 - val_loss: 0.5012 - val_accuracy: 0.7543\n",
      "Epoch 92/1000\n",
      "58/58 [==============================] - 4s 77ms/step - loss: 0.4316 - accuracy: 0.7916 - val_loss: 0.4900 - val_accuracy: 0.7783\n",
      "Epoch 93/1000\n",
      "58/58 [==============================] - 5s 83ms/step - loss: 0.4328 - accuracy: 0.7889 - val_loss: 0.4701 - val_accuracy: 0.7761\n",
      "Epoch 94/1000\n",
      "58/58 [==============================] - 14s 251ms/step - loss: 0.4397 - accuracy: 0.7976 - val_loss: 0.4808 - val_accuracy: 0.7739\n",
      "Epoch 95/1000\n",
      "58/58 [==============================] - 21s 356ms/step - loss: 0.4284 - accuracy: 0.8009 - val_loss: 0.4921 - val_accuracy: 0.7717\n",
      "Epoch 96/1000\n",
      "58/58 [==============================] - 14s 241ms/step - loss: 0.4417 - accuracy: 0.7927 - val_loss: 0.5587 - val_accuracy: 0.7348\n",
      "Epoch 97/1000\n",
      "58/58 [==============================] - 6s 111ms/step - loss: 0.4205 - accuracy: 0.8085 - val_loss: 0.5080 - val_accuracy: 0.7652\n",
      "Epoch 98/1000\n",
      "58/58 [==============================] - 6s 101ms/step - loss: 0.4328 - accuracy: 0.8107 - val_loss: 0.4516 - val_accuracy: 0.7870\n",
      "Epoch 99/1000\n",
      "58/58 [==============================] - 6s 96ms/step - loss: 0.4361 - accuracy: 0.7976 - val_loss: 0.4825 - val_accuracy: 0.7565\n",
      "Epoch 100/1000\n",
      "58/58 [==============================] - 5s 90ms/step - loss: 0.4084 - accuracy: 0.8346 - val_loss: 0.4958 - val_accuracy: 0.7609\n",
      "Epoch 101/1000\n",
      "58/58 [==============================] - 5s 87ms/step - loss: 0.4166 - accuracy: 0.7992 - val_loss: 0.4767 - val_accuracy: 0.7717\n",
      "Epoch 102/1000\n",
      "58/58 [==============================] - 5s 85ms/step - loss: 0.4391 - accuracy: 0.7922 - val_loss: 0.4623 - val_accuracy: 0.7783\n",
      "Epoch 103/1000\n",
      "58/58 [==============================] - 5s 84ms/step - loss: 0.4347 - accuracy: 0.8052 - val_loss: 0.6623 - val_accuracy: 0.6391\n",
      "Epoch 104/1000\n",
      "58/58 [==============================] - 5s 82ms/step - loss: 0.4292 - accuracy: 0.8036 - val_loss: 0.4865 - val_accuracy: 0.7783\n",
      "Epoch 105/1000\n",
      "58/58 [==============================] - 5s 81ms/step - loss: 0.4065 - accuracy: 0.8199 - val_loss: 0.5224 - val_accuracy: 0.7565\n",
      "Epoch 106/1000\n",
      "58/58 [==============================] - 5s 80ms/step - loss: 0.4272 - accuracy: 0.8036 - val_loss: 0.4859 - val_accuracy: 0.7587\n",
      "Epoch 107/1000\n",
      "58/58 [==============================] - 5s 78ms/step - loss: 0.4216 - accuracy: 0.8003 - val_loss: 0.4840 - val_accuracy: 0.7717\n",
      "Epoch 108/1000\n",
      "58/58 [==============================] - 4s 77ms/step - loss: 0.4015 - accuracy: 0.8156 - val_loss: 0.4701 - val_accuracy: 0.7848\n",
      "Epoch 109/1000\n",
      "58/58 [==============================] - 4s 76ms/step - loss: 0.4326 - accuracy: 0.7998 - val_loss: 0.5185 - val_accuracy: 0.7500\n",
      "Epoch 110/1000\n",
      "58/58 [==============================] - 4s 75ms/step - loss: 0.4200 - accuracy: 0.8161 - val_loss: 0.5473 - val_accuracy: 0.7413\n",
      "Epoch 111/1000\n",
      "58/58 [==============================] - 4s 76ms/step - loss: 0.4281 - accuracy: 0.8101 - val_loss: 0.4924 - val_accuracy: 0.7587\n",
      "Epoch 112/1000\n",
      "58/58 [==============================] - 5s 78ms/step - loss: 0.3927 - accuracy: 0.8281 - val_loss: 0.5330 - val_accuracy: 0.7391\n",
      "Epoch 113/1000\n",
      "58/58 [==============================] - 5s 82ms/step - loss: 0.3868 - accuracy: 0.8297 - val_loss: 0.5372 - val_accuracy: 0.7348\n",
      "Epoch 114/1000\n",
      "58/58 [==============================] - 10s 168ms/step - loss: 0.3974 - accuracy: 0.8139 - val_loss: 0.5223 - val_accuracy: 0.7587\n",
      "Epoch 115/1000\n",
      "58/58 [==============================] - 21s 358ms/step - loss: 0.4030 - accuracy: 0.8150 - val_loss: 0.5132 - val_accuracy: 0.7630\n",
      "Epoch 116/1000\n",
      "58/58 [==============================] - 16s 273ms/step - loss: 0.4156 - accuracy: 0.8172 - val_loss: 0.5253 - val_accuracy: 0.7609\n",
      "Epoch 117/1000\n",
      "58/58 [==============================] - 7s 113ms/step - loss: 0.3815 - accuracy: 0.8286 - val_loss: 0.9450 - val_accuracy: 0.6370\n",
      "Epoch 118/1000\n",
      "58/58 [==============================] - 6s 103ms/step - loss: 0.4267 - accuracy: 0.8003 - val_loss: 0.5431 - val_accuracy: 0.7413\n",
      "Epoch 119/1000\n",
      "58/58 [==============================] - 6s 98ms/step - loss: 0.4062 - accuracy: 0.8199 - val_loss: 0.5063 - val_accuracy: 0.7739\n",
      "Epoch 120/1000\n",
      "58/58 [==============================] - 5s 91ms/step - loss: 0.4040 - accuracy: 0.8150 - val_loss: 0.5297 - val_accuracy: 0.7696\n",
      "Epoch 121/1000\n",
      "58/58 [==============================] - 5s 91ms/step - loss: 0.3955 - accuracy: 0.8275 - val_loss: 0.4729 - val_accuracy: 0.7696\n",
      "Epoch 122/1000\n",
      "58/58 [==============================] - 5s 86ms/step - loss: 0.3943 - accuracy: 0.8205 - val_loss: 0.6548 - val_accuracy: 0.7239\n",
      "Epoch 123/1000\n",
      "58/58 [==============================] - 5s 84ms/step - loss: 0.4006 - accuracy: 0.8194 - val_loss: 0.6097 - val_accuracy: 0.7043\n",
      "Epoch 124/1000\n",
      "58/58 [==============================] - 5s 82ms/step - loss: 0.4102 - accuracy: 0.8145 - val_loss: 0.5039 - val_accuracy: 0.7739\n",
      "Epoch 125/1000\n",
      "58/58 [==============================] - 5s 81ms/step - loss: 0.4073 - accuracy: 0.8232 - val_loss: 0.5036 - val_accuracy: 0.7826\n",
      "Epoch 126/1000\n",
      "58/58 [==============================] - 5s 80ms/step - loss: 0.3883 - accuracy: 0.8226 - val_loss: 0.5866 - val_accuracy: 0.7652\n",
      "Epoch 127/1000\n",
      "58/58 [==============================] - 5s 78ms/step - loss: 0.3948 - accuracy: 0.8243 - val_loss: 0.5152 - val_accuracy: 0.7543\n",
      "Epoch 128/1000\n",
      "57/58 [============================>.] - ETA: 0s - loss: 0.3639 - accuracy: 0.8448Restoring model weights from the end of the best epoch: 98.\n",
      "58/58 [==============================] - 5s 78ms/step - loss: 0.3667 - accuracy: 0.8428 - val_loss: 0.5774 - val_accuracy: 0.7478\n",
      "Epoch 128: early stopping\n"
     ]
    }
   ],
   "source": [
    "history = model.fit(\n",
    "    x,\n",
    "    y,\n",
    "    callbacks=es,\n",
    "    epochs=1000,\n",
    "    validation_split=0.2,\n",
    "    verbose=1,\n",
    "    batch_size=BATCH_SIZE\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Using a while_loop for converting RngReadAndSkip cause there is no registered converter for this op.\n",
      "WARNING:tensorflow:Using a while_loop for converting Bitcast cause there is no registered converter for this op.\n",
      "WARNING:tensorflow:Using a while_loop for converting Bitcast cause there is no registered converter for this op.\n",
      "WARNING:tensorflow:Using a while_loop for converting StatelessRandomUniformV2 cause there is no registered converter for this op.\n",
      "WARNING:tensorflow:Using a while_loop for converting ImageProjectiveTransformV3 cause there is no registered converter for this op.\n",
      "WARNING:tensorflow:Using a while_loop for converting RngReadAndSkip cause there is no registered converter for this op.\n",
      "WARNING:tensorflow:Using a while_loop for converting Bitcast cause there is no registered converter for this op.\n",
      "WARNING:tensorflow:Using a while_loop for converting Bitcast cause there is no registered converter for this op.\n",
      "WARNING:tensorflow:Using a while_loop for converting StatelessRandomUniformFullIntV2 cause there is no registered converter for this op.\n",
      "WARNING:tensorflow:Using a while_loop for converting StatelessRandomGetKeyCounter cause there is no registered converter for this op.\n",
      "WARNING:tensorflow:Using a while_loop for converting StatelessRandomUniformV2 cause there is no registered converter for this op.\n",
      "WARNING:tensorflow:Using a while_loop for converting AdjustContrastv2 cause Input \"contrast_factor\" of op 'AdjustContrastv2' expected to be loop invariant.\n",
      "WARNING:tensorflow:Using a while_loop for converting RngReadAndSkip cause there is no registered converter for this op.\n",
      "WARNING:tensorflow:Using a while_loop for converting Bitcast cause there is no registered converter for this op.\n",
      "WARNING:tensorflow:Using a while_loop for converting Bitcast cause there is no registered converter for this op.\n",
      "WARNING:tensorflow:Using a while_loop for converting StatelessRandomUniformFullIntV2 cause there is no registered converter for this op.\n",
      "WARNING:tensorflow:Using a while_loop for converting StatelessRandomGetKeyCounter cause there is no registered converter for this op.\n",
      "WARNING:tensorflow:Using a while_loop for converting StatelessRandomUniformV2 cause there is no registered converter for this op.\n",
      "WARNING:tensorflow:Using a while_loop for converting AdjustContrastv2 cause Input \"contrast_factor\" of op 'AdjustContrastv2' expected to be loop invariant.\n",
      "WARNING:tensorflow:Using a while_loop for converting RngReadAndSkip cause there is no registered converter for this op.\n",
      "WARNING:tensorflow:Using a while_loop for converting Bitcast cause there is no registered converter for this op.\n",
      "WARNING:tensorflow:Using a while_loop for converting Bitcast cause there is no registered converter for this op.\n",
      "WARNING:tensorflow:Using a while_loop for converting StatelessRandomUniformV2 cause there is no registered converter for this op.\n",
      "WARNING:tensorflow:Using a while_loop for converting ImageProjectiveTransformV3 cause there is no registered converter for this op.\n",
      "WARNING:tensorflow:Using a while_loop for converting RngReadAndSkip cause there is no registered converter for this op.\n",
      "WARNING:tensorflow:Using a while_loop for converting Bitcast cause there is no registered converter for this op.\n",
      "WARNING:tensorflow:Using a while_loop for converting Bitcast cause there is no registered converter for this op.\n",
      "WARNING:tensorflow:Using a while_loop for converting StatelessRandomUniformFullIntV2 cause there is no registered converter for this op.\n",
      "WARNING:tensorflow:Using a while_loop for converting StatelessRandomGetKeyCounter cause there is no registered converter for this op.\n",
      "WARNING:tensorflow:Using a while_loop for converting StatelessRandomUniformV2 cause there is no registered converter for this op.\n",
      "WARNING:tensorflow:Using a while_loop for converting AdjustContrastv2 cause Input \"contrast_factor\" of op 'AdjustContrastv2' expected to be loop invariant.\n",
      "WARNING:tensorflow:Using a while_loop for converting RngReadAndSkip cause there is no registered converter for this op.\n",
      "WARNING:tensorflow:Using a while_loop for converting Bitcast cause there is no registered converter for this op.\n",
      "WARNING:tensorflow:Using a while_loop for converting Bitcast cause there is no registered converter for this op.\n",
      "WARNING:tensorflow:Using a while_loop for converting StatelessRandomUniformV2 cause there is no registered converter for this op.\n",
      "WARNING:tensorflow:Using a while_loop for converting ImageProjectiveTransformV3 cause there is no registered converter for this op.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op while saving (showing 5 of 6). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: /home/fernandofincatti/.cascid_data/experiments/fernando/models/deep_learning/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: /home/fernandofincatti/.cascid_data/experiments/fernando/models/deep_learning/assets\n"
     ]
    }
   ],
   "source": [
    "model.save(MODEL_PATH)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "setting an array element with a sequence.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;31mTypeError\u001b[0m: only size-1 arrays can be converted to Python scalars",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m/home/fernandofincatti/Documents/insper/pfe/ComputerAidedSkinCancerIdentificationAndDiagnosis/experiments/fernando/transfer-learning/pad-ufes/test04/binary-classifier.ipynb Cell 26\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      <a href='vscode-notebook-cell:/home/fernandofincatti/Documents/insper/pfe/ComputerAidedSkinCancerIdentificationAndDiagnosis/experiments/fernando/transfer-learning/pad-ufes/test04/binary-classifier.ipynb#ch0000035?line=0'>1</a>\u001b[0m model\u001b[39m.\u001b[39mevaluate(\n\u001b[0;32m----> <a href='vscode-notebook-cell:/home/fernandofincatti/Documents/insper/pfe/ComputerAidedSkinCancerIdentificationAndDiagnosis/experiments/fernando/transfer-learning/pad-ufes/test04/binary-classifier.ipynb#ch0000035?line=1'>2</a>\u001b[0m     np\u001b[39m.\u001b[39;49masarray(X_test)\u001b[39m.\u001b[39;49mastype(np\u001b[39m.\u001b[39;49mfloat32),\n\u001b[1;32m      <a href='vscode-notebook-cell:/home/fernandofincatti/Documents/insper/pfe/ComputerAidedSkinCancerIdentificationAndDiagnosis/experiments/fernando/transfer-learning/pad-ufes/test04/binary-classifier.ipynb#ch0000035?line=2'>3</a>\u001b[0m     np\u001b[39m.\u001b[39masarray(y_test)\u001b[39m.\u001b[39mastype(np\u001b[39m.\u001b[39mfloat32))\n",
      "\u001b[0;31mValueError\u001b[0m: setting an array element with a sequence."
     ]
    }
   ],
   "source": [
    "model.evaluate(\n",
    "    np.asarray(X_test).astype(np.float32),\n",
    "    np.asarray(y_test).astype(np.float32))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.4 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "916dbcbb3f70747c44a77c7bcd40155683ae19c65e1c03b4aa3499c5328201f1"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
