{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ResNet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import cv2\n",
    "import sklearn\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from functools import partial\n",
    "import pickle as pk\n",
    "\n",
    "from tensorflow import keras\n",
    "from keras.models import Sequential, load_model\n",
    "from keras.layers import Input, Dense, Dropout, Flatten\n",
    "from keras.layers import Conv2D, MaxPooling2D\n",
    "from keras.layers import RandomBrightness, RandomContrast, RandomCrop, RandomFlip, RandomRotation\n",
    "from keras.callbacks import EarlyStopping\n",
    "\n",
    "from cascid.configs.config import DATA_DIR\n",
    "\n",
    "IMAGE_SIZE = (256,256,3)\n",
    "RANDOM_STATE = 42\n",
    "METRICS = ['loss', 'acc', 'auc']\n",
    "\n",
    "EXPERIMENT_DIR = DATA_DIR / 'experiments'\n",
    "MODEL_PATH = DATA_DIR / 'dip' / 'model_resnet_noreg_aug'\n",
    "MODEL_PATH.mkdir(exist_ok=True, parents=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from cascid.datasets.pad_ufes import database, images\n",
    "from cascid.image.apply_preprocessing import remove_hair\n",
    "\n",
    "df = database.get_df()\n",
    "df.head(5).transpose()\n",
    "im = df['img_id']\n",
    "remove_hair(im.to_list())\n",
    "x = df['img_id'].apply(lambda x: images.get_hairless_image(x, IMAGE_SIZE[:2])).to_numpy()\n",
    "x = np.array([x[i] for i in range(len(x))])\n",
    "OHE = OneHotEncoder(sparse=False)\n",
    "y=df['diagnostic'].apply(lambda x: \"Cancer\" if x in ['MEL', 'SCC', 'BCC'] else \"Not\").to_numpy().reshape(-1,1)\n",
    "y = OHE.fit_transform(y)\n",
    "x_train, x_test, y_train, y_test = train_test_split(x, y, test_size=0.1, random_state=42)\n",
    "print(\"x_train shape: {0}\".format(x_train.shape))\n",
    "print(\"x_test shape: {0}\".format(x_test.shape))\n",
    "print(\"y_train shape: {0}\".format(y_train.shape))\n",
    "print(\"y_test shape: {0}\".format(y_test.shape))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ResNet(amt_64, amt_128, amt_256, amt_512, augmentation = False):\n",
    "    # Aurelien Geron, Hands-On Machine Learning with Scikit-Learn, Keras & Tensorflow.\n",
    "    DefaultConv2D = partial(keras.layers.Conv2D, kernel_size=3, strides=1, padding=\"SAME\", use_bias=False)# , kernel_regularizer=keras.regularizers.l1(l1=0.01)\n",
    "\n",
    "    class ResidualUnit(keras.layers.Layer):\n",
    "        def __init__(self, filters, strides=1, activation=\"relu\", **kwargs):\n",
    "            super().__init__(**kwargs)\n",
    "            self.activation = keras.activations.get(activation)\n",
    "            self.main_layers = [\n",
    "                DefaultConv2D(filters, strides=strides), \n",
    "                keras.layers.BatchNormalization(),\n",
    "                self.activation,\n",
    "                DefaultConv2D(filters),\n",
    "                keras.layers.BatchNormalization(),\n",
    "                keras.layers.SpatialDropout2D(0.3)\n",
    "            ]\n",
    "            self.skip_layers = []\n",
    "            if strides > 1:\n",
    "                self.skip_layers = [\n",
    "                    DefaultConv2D(filters, kernel_size=1, strides=strides),\n",
    "                    keras.layers.BatchNormalization()\n",
    "                ]\n",
    "        def call(self, inputs):\n",
    "            Z = inputs\n",
    "            for layer in self.main_layers:\n",
    "                Z = layer(Z)\n",
    "            skip_Z = inputs\n",
    "            for layer in self.skip_layers:\n",
    "                skip_Z = layer(skip_Z)\n",
    "            return self.activation(Z + skip_Z)\n",
    "\n",
    "    model = keras.models.Sequential()\n",
    "    model.add(Input(shape=IMAGE_SIZE))\n",
    "    if augmentation:\n",
    "        # model.add(RandomBrightness(factor=(-0.2, 0.2), value_range=(0.0, 1.0), seed=RANDOM_STATE) # Randomly change brightness anywhere from -30% to +30%\n",
    "        # model.add(RandomContrast(factor=0.5, seed=RANDOM_STATE)) # Randomly change contrast anywhere from -30% to +30%\n",
    "        model.add(RandomFlip(mode=\"horizontal_and_vertical\", seed=RANDOM_STATE)), # Randomly flip images either horizontally, vertically or both\n",
    "        model.add(RandomRotation(factor=(-0.2, 0.2), fill_mode=\"nearest\", interpolation=\"bilinear\", seed=RANDOM_STATE)) # Randomly rotate anywhere from -30% * 2PI to +30% * 2PI, filling gaps by using 'nearest' strategy)\n",
    "        model.add(DefaultConv2D(64, kernel_size=7, strides=2))\n",
    "    else:\n",
    "        model.add(DefaultConv2D(64, kernel_size=7, strides=2))\n",
    "    model.add(keras.layers.BatchNormalization())\n",
    "    model.add(keras.layers.Activation(\"relu\"))\n",
    "    model.add(keras.layers.MaxPool2D(pool_size=3, strides=2, padding=\"SAME\"))\n",
    "    prev_filters = 64\n",
    "    for filters in [64] * amt_64 + [128] * amt_128 + [256] * amt_256 + [512] * amt_512:\n",
    "        strides = 1 if filters == prev_filters else 2\n",
    "        model.add(ResidualUnit(filters, strides=strides))\n",
    "        prev_filters = filters\n",
    "    model.add(keras.layers.GlobalAvgPool2D())\n",
    "    model.add(keras.layers.Flatten())\n",
    "    model.add(keras.layers.Dense(2, activation=\"softmax\"))\n",
    "    return model\n",
    "\n",
    "def dump_results(model, history, path):\n",
    "    model.save(path)\n",
    "\n",
    "    with open(path / \"history.pkl\", \"wb\") as fl:\n",
    "        pk.dump(history, fl)\n",
    "\n",
    "def load_results(path):\n",
    "    model= load_model(path)\n",
    "\n",
    "    with open(path / \"history.pkl\", \"wb\") as fl:\n",
    "        history = pk.load(fl)\n",
    "    \n",
    "    return model, history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 'resnet18': (2, 2, 2, 2)\n",
    "# 'resnet34': (3, 4, 6, 3)\n",
    "\n",
    "model = ResNet(3,4,6,3, augmentation=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(\n",
    "    optimizer=keras.optimizers.Adam(learning_rate=0.001),\n",
    "    loss=keras.losses.BinaryCrossentropy(),\n",
    "    metrics=METRICS.remove('loss') # loss is implied\n",
    ")\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "history = model.fit(\n",
    "    x_train,\n",
    "    y_train,\n",
    "    epochs=100,\n",
    "    batch_size=128,\n",
    "    validation_split=0.15\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dump_results(model, history, MODEL_PATH)\n",
    "model, history = load_results(MODEL_PATH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Merge history from multiple steps\n",
    "# with open(MODEL_PATH / 'history.pkl', 'rb') as fl:\n",
    "#     h = pk.load(fl)\n",
    "\n",
    "# for k in h.keys():\n",
    "#     history[k] = h[k] + history[k]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for m in METRICS:\n",
    "    train_m = history[m]\n",
    "    val_m = history['val_'+m]\n",
    "    x = range(len(train_m))\n",
    "    plt.title(\"History: \" + m)\n",
    "    plt.plot(x, train_m, label='train')\n",
    "    plt.plot(x, val_m, label='val')\n",
    "    plt.ylim((0, 1.1))\n",
    "    plt.legend()\n",
    "    plt.show();"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.6 ('dell')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "6dc1564da09cba32049585eb0f8312288c03cc3344cb8faac4fd8e3be7299e4f"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
