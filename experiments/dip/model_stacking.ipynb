{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mCanceled future for execute_request message before replies were done"
     ]
    },
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mThe Kernel crashed while executing code in the the current cell or a previous cell. Please review the code in the cell(s) to identify a possible cause of the failure. Click <a href='https://aka.ms/vscodeJupyterKernelCrash'>here</a> for more info. View Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "#basic\n",
    "import os\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import joblib\n",
    "import pickle as pk\n",
    "\n",
    "os.environ['TF_CPP_MIN_LOG_LEVEL'] = '3' # Hide tf warnings\n",
    "#tensorflow and keras\n",
    "from tensorflow import keras, config\n",
    "from keras.models import load_model, Model\n",
    "\n",
    "#sklearn\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.metrics import confusion_matrix, accuracy_score, roc_auc_score, classification_report\n",
    "\n",
    "# cascid\n",
    "from cascid.models.StackedModel import StackedModel\n",
    "from cascid.configs.config import DATA_DIR\n",
    "from cascid.configs.pad_ufes_cnf import PAD_UFES_DIR\n",
    "from cascid.datasets.pad_ufes import database as pad_ufes\n",
    "from cascid.datasets.pad_ufes import images\n",
    "from cascid.datasets.isic import database as isic\n",
    "\n",
    "RANDOM_STATE = 42\n",
    "NN_PATH = DATA_DIR / 'experiments_final' / 'final_isic' / 'resnet34' / 'aug_hq' / 'checkpoint_epoch0075'\n",
    "RFC_PATH = PAD_UFES_DIR / 'rfc_clf_bin_final.joblib'\n",
    "OUTPUT_PATH = DATA_DIR / 'final_models' / 'stacked_02'\n",
    "OUTPUT_PATH.mkdir(exist_ok=True, parents=True)\n",
    "\n",
    "def plot_confusion_matrix(y_true, y_pred, classes,\n",
    "                          normalize=True,\n",
    "                          title=None,\n",
    "                          cmap=plt.cm.Blues, save_to_file = False):\n",
    "    if not title:\n",
    "        if normalize:\n",
    "            title = 'Normalized confusion matrix'\n",
    "        else:\n",
    "            title = 'Confusion matrix, without normalization'\n",
    "\n",
    "    # Compute confusion matrix\n",
    "    cm = confusion_matrix(y_true, y_pred)\n",
    "    if normalize:\n",
    "        cm = cm.astype('float') / cm.sum(axis=1)[:, np.newaxis]\n",
    "        #print(\"Normalized confusion matrix\")\n",
    "    else:\n",
    "        print('Confusion matrix, without normalization')\n",
    "\n",
    "    #print(cm)\n",
    "\n",
    "    fig, ax = plt.subplots(figsize = (5,5))\n",
    "    im = ax.imshow(cm, interpolation='nearest', cmap=cmap)\n",
    "    # ax.figure.colorbar(im, ax=ax)\n",
    "    ax.set(xticks=np.arange(cm.shape[1]),\n",
    "           yticks=np.arange(cm.shape[0]),\n",
    "           xticklabels=classes, yticklabels=classes,\n",
    "           title=title,\n",
    "           ylabel='True label',\n",
    "           xlabel='Predicted label')\n",
    "\n",
    "    plt.setp(ax.get_xticklabels(), rotation=45, ha=\"right\",\n",
    "             rotation_mode=\"anchor\")\n",
    "\n",
    "    fmt = '.2f' if normalize else 'd'\n",
    "    thresh = 0.5\n",
    "    for i in range(cm.shape[0]):\n",
    "        for j in range(cm.shape[1]):\n",
    "            ax.text(j, i, format(cm[i, j], fmt),\n",
    "                    ha=\"center\", va=\"center\",\n",
    "                    color=\"white\" if cm[i, j] > thresh else \"black\")\n",
    "    fig.tight_layout()\n",
    "    if save_to_file:\n",
    "        plt.savefig('Assets/files/' + title + '.pdf')\n",
    "    return ax\n",
    "\n",
    "rfc = joblib.load(RFC_PATH)\n",
    "NN = load_model(NN_PATH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "StackModel = StackedModel(NN, rfc)\n",
    "StackModel_2 = StackedModel(NN, rfc, NN_include_top=False)\n",
    "\n",
    "x_train_metadata, x_train_stacked, x_test, y_train_metadata, y_train_stacked, y_test = pad_ufes.get_train_test_metadata(return_img_id=True)\n",
    "image_shape = (256,256,3) # StackModel.get_input_image_shape()\n",
    "\n",
    "x_train_nn = x_train_stacked['img_id']\n",
    "x_train_nn = x_train_nn.apply(lambda img_id : images.get_hq_image(img_id, image_shape=image_shape)).to_numpy()\n",
    "x_train_nn = np.array([i for i in x_train_nn])\n",
    "x_train_rfc = x_train_stacked.drop('img_id', axis=1).to_numpy().astype(np.float64)\n",
    "\n",
    "\n",
    "x_test_nn = x_test['img_id']\n",
    "x_test_nn = x_test_nn.apply(lambda img_id : images.get_hq_image(img_id, image_shape=image_shape)).to_numpy()\n",
    "x_test_rfc = x_test.drop('img_id', axis=1).to_numpy().astype(np.float64)\n",
    "x_test_nn = np.array([i for i in x_test_nn])\n",
    "\n",
    "StackModel.fit(x_train_nn, x_train_rfc, y_train_stacked)\n",
    "StackModel_2.fit(x_train_nn, x_train_rfc, y_train_stacked)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Using NN as classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "preds_train = StackModel.predict(x_train_nn, x_train_rfc)\n",
    "preds_test = StackModel.predict(x_test_nn, x_test_rfc)\n",
    "plot_confusion_matrix(y_train_stacked, preds_train, sorted([\"Not\", \"Cancer\"]), title=\"Train\")\n",
    "plot_confusion_matrix(y_test, preds_test, sorted([\"Not\", \"Cancer\"]), title=\"Test\")\n",
    "acc = accuracy_score(y_true=y_test, y_pred=preds_test)\n",
    "print(\"Accuracy: {:.3f}%\".format(100*acc))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Using NN as feature extractor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "preds_train = StackModel_2.predict(x_train_nn, x_train_rfc)\n",
    "preds_test = StackModel_2.predict(x_test_nn, x_test_rfc)\n",
    "plot_confusion_matrix(y_train_stacked, preds_train, sorted([\"Not\", \"Cancer\"]), title=\"Train\")\n",
    "plot_confusion_matrix(y_test, preds_test, sorted([\"Not\", \"Cancer\"]), title=\"Test\")\n",
    "acc = accuracy_score(y_true=y_test, y_pred=preds_test)\n",
    "print(\"Accuracy: {:.3f}%\".format(100*acc))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Hyperparameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    with open(DATA_DIR / 'pred_cache.pickle', 'rb') as f:\n",
    "        p = pk.load(f)\n",
    "    x_train_nn = p[\"x_train_nn\"]\n",
    "    x_train_nn_features = p[\"x_train_nn_features\"]\n",
    "    x_train_rfc = p[\"x_train_rfc\"]\n",
    "    x_test_nn = p[\"x_test_nn\"]\n",
    "    x_test_rfc = p[\"x_test_rfc\"]\n",
    "    x_train_nn_classification = p[\"x_train_nn_classification\"]\n",
    "    x_train_metadata_classification = p[\"x_train_metadata_classification\"]\n",
    "    x_test_nn_features = p[\"x_test_nn_features\"]\n",
    "    x_test_nn_classification = p[\"x_test_nn_classification\"]\n",
    "    x_test_metadata_classification = p[\"x_test_metadata_classification\"]\n",
    "    x_train_features = p[\"x_train_features\"]\n",
    "    x_train_classification = p[\"x_train_classification\"]\n",
    "    x_test_features = p[\"x_test_features\"]\n",
    "    x_test_classification = p[\"x_test_classification\"]\n",
    "    y_train_metadata = p[\"y_train_metadata\"] \n",
    "    y_train_stacked = p[\"y_train_stacked\"] \n",
    "    y_test = p[\"y_test\"]\n",
    "except (FileNotFoundError, KeyError) as e:\n",
    "    feature_extractor = Model(inputs = NN.input, outputs=NN.layers[-2].output) # Model outputing last layer before classification layer\n",
    "    x_train_nn_features = feature_extractor.predict(x_train_nn)\n",
    "    x_train_nn_classification = NN.predict(x_train_nn)\n",
    "    x_train_metadata_classification = rfc.predict_proba(x_train_rfc)\n",
    "    x_test_nn_features = feature_extractor.predict(x_test_nn)\n",
    "    x_test_nn_classification = NN.predict(x_test_nn)\n",
    "    x_test_metadata_classification = rfc.predict_proba(x_test_rfc)\n",
    "    x_train_features = np.hstack([x_train_nn_features, x_train_metadata_classification])\n",
    "    x_train_classification = np.hstack([x_train_nn_classification, x_train_metadata_classification])\n",
    "    x_test_features = np.hstack([x_test_nn_features, x_test_metadata_classification])\n",
    "    x_test_classification = np.hstack([x_test_nn_classification, x_test_metadata_classification])\n",
    "\n",
    "    preds = {\n",
    "        \"x_train_nn\" : x_train_nn,\n",
    "        \"x_train_nn_features\": x_train_nn_features,\n",
    "        \"x_train_rfc\" : x_train_rfc,\n",
    "        \"x_test_nn\" : x_test_nn,\n",
    "        \"x_test_rfc\" : x_test_rfc,\n",
    "        \"x_train_nn_classification\": x_train_nn_classification,\n",
    "        \"x_train_metadata_classification\": x_train_metadata_classification,\n",
    "        \"x_test_nn_features\": x_test_nn_features,\n",
    "        \"x_test_nn_classification\": x_test_nn_classification,\n",
    "        \"x_test_metadata_classification\": x_test_metadata_classification,\n",
    "        \"x_train_features\": x_train_features,\n",
    "        \"x_train_classification\": x_train_classification,\n",
    "        \"x_test_features\": x_test_features,\n",
    "        \"x_test_classification\": x_test_classification,\n",
    "        \"y_train_metadata\" : y_train_metadata,\n",
    "        \"y_train_stacked\" : y_train_stacked,\n",
    "        \"y_test\" : y_test,\n",
    "    }\n",
    "    with open(DATA_DIR / 'pred_cache.pickle', 'wb') as f:\n",
    "        pk.dump(preds, f)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "params = {\n",
    "    \"max_samples\" : list(np.arange(0.15, 0.26, 0.01)),\n",
    "    \"n_estimators\" : list(range(350, 401, 5)),\n",
    "    \"max_depth\" : list(range(7,14)),\n",
    "}\n",
    "\n",
    "rfc = RandomForestClassifier(random_state=42)\n",
    "CV_rfc = GridSearchCV(rfc, param_grid=params, cv=5, n_jobs=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "CV_rfc.fit(x_train_features, y_train_stacked)\n",
    "best_features_rfc = CV_rfc.best_estimator_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rfc = RandomForestClassifier(random_state=42)\n",
    "CV_rfc = GridSearchCV(rfc, param_grid=params, cv=5, n_jobs=-1)\n",
    "CV_rfc.fit(x_train_classification, y_train_stacked)\n",
    "best_classification_rfc = CV_rfc.best_estimator_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Performance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "preds_train = best_classification_rfc.predict(x_train_classification)\n",
    "preds_test = best_classification_rfc.predict(x_test_classification)\n",
    "plot_confusion_matrix(y_train_stacked, preds_train, sorted([\"Not\", \"Cancer\"]), title=\"Train NNClassif\")\n",
    "plot_confusion_matrix(y_test, preds_test, sorted([\"Not\", \"Cancer\"]), title=\"Test NNClassif\")\n",
    "acc = accuracy_score(y_true=y_test, y_pred=preds_test)\n",
    "print(\"Accuracy: {:.3f}%\".format(100*acc))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "preds_train = best_features_rfc.predict(x_train_features)\n",
    "preds_test = best_features_rfc.predict(x_test_features)\n",
    "plot_confusion_matrix(y_train_stacked, preds_train, sorted([\"Not\", \"Cancer\"]), title=\"Train NNFeatures\")\n",
    "plot_confusion_matrix(y_test, preds_test, sorted([\"Not\", \"Cancer\"]), title=\"Test NNFeatures\")\n",
    "acc = accuracy_score(y_true=y_test, y_pred=preds_test)\n",
    "print(\"Accuracy: {:.3f}%\".format(100*acc))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(best_features_rfc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Sens/Spec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def apply_threshold(thr, preds):\n",
    "    return [\"Cancer\" if i[0] > thr else \"Not\" for i in preds]\n",
    "preds_best_proba = best_features_rfc.predict_proba(x_test_features)\n",
    "\n",
    "res = list()\n",
    "for i in np.arange(0.05, 0.87, 0.001):\n",
    "    rep = classification_report(y_test, apply_threshold(i, preds_best_proba), output_dict=True)\n",
    "    sens, spec = rep['Cancer']['recall'], rep['Not']['recall']\n",
    "    res.append([i, sens, spec])\n",
    "res = np.array(res)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "thr = res[:,0]\n",
    "sensitivity = res[:,1]\n",
    "specificity = res[:,2]\n",
    "\n",
    "i = 0\n",
    "s = sensitivity[i]\n",
    "while s > 0.734:\n",
    "    i+=1\n",
    "    s = sensitivity[i]\n",
    "print(\"Closest performance to doctor would be:\\nsensitivity={}\\nspecificity={}\".format(sensitivity[i], specificity[i]))\n",
    "\n",
    "SIZE=(6,4)\n",
    "plt.figure(figsize=SIZE)\n",
    "plt.plot(sensitivity, specificity);\n",
    "plt.axvline(0.743, label=\"Doctor\", c='g', alpha=0.6, ls='--')\n",
    "plt.title(\"Sensitivity x Specificity\")\n",
    "plt.xlabel(\"Sensitivity\")\n",
    "plt.ylabel(\"Specificity\")\n",
    "plt.scatter(sensitivity[i], specificity[i], c='r')\n",
    "plt.annotate(\"({:.2f},{:.2f})\".format(sensitivity[i], specificity[i]), (sensitivity[i]+0.05, specificity[i]+0.05))\n",
    "plt.legend(loc=3)\n",
    "plt.show()\n",
    "\n",
    "plt.figure(figsize=SIZE)\n",
    "plt.plot(thr, specificity,label='Specificity')\n",
    "plt.plot(thr, sensitivity,label='Sensitivity')\n",
    "plt.axhline(0.743, label=\"Doctor Sensitivity\", c='g', alpha=0.6, ls='--')\n",
    "plt.title(\"Recall by class for thresholds\")\n",
    "plt.xlabel(\"Threshold\")\n",
    "plt.ylabel(\"Recall\")\n",
    "plt.scatter(thr[i], sensitivity[i], c='r')\n",
    "plt.scatter(thr[i], specificity[i], c='r')\n",
    "plt.annotate(\"({:.2f},{:.2f})\".format(thr[i], sensitivity[i]), (thr[i], sensitivity[i]+0.05))\n",
    "plt.annotate(\"({:.2f},{:.2f})\".format(thr[i], specificity[i]), (thr[i], specificity[i]-0.05))\n",
    "plt.legend()\n",
    "plt.show();\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Saving best"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "best = StackedModel(NN, joblib.load(RFC_PATH), NN_include_top=True, stacker_model=RandomForestClassifier(max_depth=10, max_samples=0.19, n_estimators=360, random_state=42))\n",
    "best.fit(x_train_nn, x_train_rfc, y_train_stacked)\n",
    "best.save(OUTPUT_PATH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sm_load = StackedModel.load(OUTPUT_PATH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sm_load.predict_proba(x_train_nn[:1], [x_train_rfc[0]])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.6 ('dell')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "6dc1564da09cba32049585eb0f8312288c03cc3344cb8faac4fd8e3be7299e4f"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
