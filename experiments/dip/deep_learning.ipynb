{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## TRANSFER LEARNING: IMPROVING ALGORITHM\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "import os\n",
    "\n",
    "#basic\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "#tensorflow and keras\n",
    "from tensorflow import keras\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from keras.layers import Input, Dense, GlobalAveragePooling2D, Flatten, MaxPooling2D, Dropout, Resizing, Rescaling, RandomBrightness, RandomContrast, RandomCrop, RandomFlip, RandomRotation\n",
    "from keras.callbacks import ModelCheckpoint, EarlyStopping\n",
    "from keras import Model\n",
    "from keras.utils import load_img, img_to_array\n",
    "\n",
    "#sklearn\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "\n",
    "#open cv\n",
    "import cv2 as cv\n",
    "\n",
    "\n",
    "from cascid.configs import config, pad_ufes\n",
    "from cascid import database"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Constants"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# PATH = \"/home/fernandofincatti/Documents/insper/pfe/ComputerAidedSkinCancerIdentificationAndDiagnosis/data/\"\n",
    "RANDOM_STATE = 42\n",
    "TRAIN_SIZE = 0.7\n",
    "VALIDATION_SIZE = 0.15\n",
    "TEST_SIZE = 0.15\n",
    "EPOCHS = 3000\n",
    "IMAGE_SHAPE = (256, 256, 3)\n",
    "\n",
    "FERNANDO_PATH = config.DATA_DIR / 'experiments' / 'fernando'\n",
    "FERNANDO_PATH.mkdir(exist_ok=True, parents=True)\n",
    "\n",
    "IMAGE_CACHE = FERNANDO_PATH / 'img_cache.pkl'\n",
    "FEATURES_FILE = FERNANDO_PATH / 'features.pkl'\n",
    "MODEL_PATH = FERNANDO_PATH / 'models' / 'deep_learning'\n",
    "\n",
    "COMPUTE_FEATURES = True\n",
    "FORCE_IMAGE_CACHE = False\n",
    "TRAIN_MODEL = True\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Loading data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = database.get_db()\n",
    "df.head(5).transpose()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Split train, validation and test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "MulticlassEncoder = OneHotEncoder(sparse=False)\n",
    "Y = MulticlassEncoder.fit_transform(df[[\"diagnostic\"]].to_numpy())\n",
    "x_train, x_test, y_train, y_test = train_test_split(df[\"img_id\"].to_numpy(), Y, test_size=0.2, random_state=RANDOM_STATE)\n",
    "x_train, x_valid, y_train, y_valid = train_test_split(x_train, y_train, test_size=0.2, random_state=RANDOM_STATE)\n",
    "\n",
    "print(\"x_train shape: {0}\".format(x_train.shape))\n",
    "print(\"x_validation shape: {0}\".format(x_valid.shape))\n",
    "print(\"x_test shape: {0}\".format(x_test.shape))\n",
    "\n",
    "print(\"y_train shape: {0}\".format(y_train.shape))\n",
    "print(\"y_validation shape: {0}\".format(y_valid.shape))\n",
    "print(\"y_test shape: {0}\".format(y_test.shape))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Image Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_image(name: str):\n",
    "    pil_img = load_img(\n",
    "        str(pad_ufes.IMAGES_DIR / name),\n",
    "        grayscale=False,\n",
    "        color_mode='rgb',\n",
    "        target_size=(IMAGE_SHAPE[0], IMAGE_SHAPE[1]),\n",
    "        interpolation='nearest',\n",
    "        keep_aspect_ratio=False\n",
    "    )\n",
    "\n",
    "    return img_to_array(pil_img, dtype=np.uint8)\n",
    "\n",
    "plt.imshow(load_image(x_train[7]))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Image Loading and cache"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Automatic caching of image read operations (slow)\n",
    "if not os.path.exists(IMAGE_CACHE) or FORCE_IMAGE_CACHE:\n",
    "    print(\"Cache not found, doing read operations...\")\n",
    "    reader = lambda img_path_list : np.array(list(map(load_image, img_path_list)))\n",
    "    image_dict = {\n",
    "        \"train\": reader(x_train),\n",
    "        \"test\": reader(x_test),\n",
    "        \"valid\": reader(x_valid)\n",
    "    }\n",
    "    with open(IMAGE_CACHE, 'wb') as file:\n",
    "        pickle.dump(image_dict, file)\n",
    "    print(\"Read operation done, cache file available at {}\".format(IMAGE_CACHE))\n",
    "else:\n",
    "    with open(IMAGE_CACHE, 'rb') as file:\n",
    "        image_dict = pickle.load(file)\n",
    "\n",
    "# Return to original variables\n",
    "x_train = image_dict[\"train\"]\n",
    "x_test = image_dict[\"test\"]\n",
    "x_valid = image_dict[\"valid\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data augmentation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train_data_augmentation_generator = ImageDataGenerator(\n",
    "#     rotation_range=20,\n",
    "#     width_shift_range=0.2,\n",
    "#     height_shift_range=0.2,\n",
    "#     horizontal_flip=True,\n",
    "# )\n",
    "\n",
    "input_layer = keras.Sequential([\n",
    "    Rescaling(1./255), # Rescale from 0 to 255 UINT8 to 0 to 1 float.\n",
    "])\n",
    "\n",
    "augmentor = keras.Sequential([\n",
    "    RandomBrightness(factor=(-0.3, 0.3), value_range=(0.0, 1.0), seed=RANDOM_STATE), # Randomly change brightness anywhere from -30% to +30%\n",
    "    RandomContrast(factor=0.5, seed=RANDOM_STATE), # Randomly change contrast anywhere from -30% to +30%\n",
    "    RandomFlip(mode=\"horizontal_and_vertical\", seed=RANDOM_STATE), # Randomly flip images either horizontally, vertically or both\n",
    "    RandomRotation(factor=(-0.3, 0.3), fill_mode=\"nearest\", interpolation=\"bilinear\", seed=RANDOM_STATE), # Randomly rotate anywhere from -30% * 2PI to +30% * 2PI, filling gaps by using 'nearest' strategy\n",
    "])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if COMPUTE_FEATURES:\n",
    "    resnet = keras.applications.ResNet50(\n",
    "        weights='imagenet',\n",
    "        input_shape=IMAGE_SHAPE,\n",
    "        pooling='avg',\n",
    "        include_top=False,\n",
    "    )\n",
    "    resnet.trainable = False  #to make sure it's not being trained\n",
    "    # Augmentation only on training\n",
    "    feature_extractor_train = keras.Sequential([\n",
    "        input_layer,\n",
    "        augmentor,\n",
    "        resnet\n",
    "    ])\n",
    "    # Test/Validation only get rescaled\n",
    "    feature_extractor_test_valid = keras.Sequential([\n",
    "        input_layer,\n",
    "        resnet\n",
    "    ])\n",
    "    features_train = feature_extractor_train(x_train[:5])\n",
    "    features_valid = feature_extractor_test_valid(x_valid[:5])\n",
    "    features_test = feature_extractor_test_valid(x_test[:5])\n",
    "\n",
    "    features = {\n",
    "        \"train\": features_train.numpy(),\n",
    "        \"test\": features_test.numpy(),\n",
    "        \"valid\": features_valid.numpy()\n",
    "    }\n",
    "\n",
    "    with open(FEATURES_FILE, 'wb') as file:\n",
    "        pickle.dump(features, file)\n",
    "else:\n",
    "    with open(FEATURES_FILE, 'rb') as file:\n",
    "        features = pickle.load(file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f'{features[\"train\"].shape=}\\n{features[\"test\"].shape=}\\n{features[\"valid\"].shape=}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = keras.Sequential([\n",
    "    Input(shape = features[\"train\"].shape[1]),\n",
    "    Dense(64, activation='relu'),\n",
    "    Dropout(0.3),\n",
    "    Dense(32),\n",
    "    Dropout(0.2),\n",
    "    Dense(16),\n",
    "    Dropout(0.2),\n",
    "    Dense(y_train.shape[1], activation='softmax')\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(optimizer='adam',\n",
    "              loss='categorical_crossentropy',\n",
    "              metrics=['accuracy'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_model_checkpoint_early_stopping = EarlyStopping(\n",
    "    monitor='val_accuracy',\n",
    "    mode='max',\n",
    "    verbose=1,\n",
    "    patience=100,\n",
    "    restore_best_weights=True\n",
    ")\n",
    "\n",
    "best_model_checkpoint = ModelCheckpoint(\n",
    "    filepath=\n",
    "    \"/home/fernandofincatti/Documents/insper/pfe/ComputerAidedSkinCancerIdentificationAndDiagnosis/experiments/fernando/transfer-learning/test02/model\",\n",
    "    monitor='val_accuracy',\n",
    "    save_best_only=True,\n",
    "    save_weights_only=True\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if TRAIN_MODEL:\n",
    "\n",
    "    training_history = model.fit(\n",
    "        features[\"train\"],\n",
    "        y_train,\n",
    "        epochs=EPOCHS,\n",
    "        validation_split=0.2,\n",
    "        batch_size=512,\n",
    "        #callbacks=[best_model_checkpoint, best_model_checkpoint_early_stopping]\n",
    "    )\n",
    "\n",
    "    model.save(MODEL_PATH)\n",
    "\n",
    "    with open(MODEL_PATH / 'history.pkl', 'wb') as fl:\n",
    "        pickle.dump(training_history.history)\n",
    "\n",
    "else:\n",
    "\n",
    "    print(\"Load model\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.DataFrame(training_history.history).plot(figsize=(8, 5))\n",
    "plt.grid(True)\n",
    "plt.xlabel(\"Epochs\")\n",
    "plt.ylabel(\"Categorical Crossentropy (loss)\")\n",
    "plt.ylim((0,10))\n",
    "plt.title(\"Model History\")\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Evaluating the model"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.10 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "31f2aee4e71d21fbe5cf8b01ff0e069b9275f58929596ceb00d14d90e3e16cd6"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
